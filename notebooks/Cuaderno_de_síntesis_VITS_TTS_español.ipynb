{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/Cuaderno_de_s%C3%ADntesis_VITS_TTS_espa%C3%B1ol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><font color=\"pink\" size=\"+2\">  Cuaderno de síntesis en español de [VITS TTS](https://github.com/jaywalnut310/vits): Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Cuaderno desarrollado por: [rmcpantoja](https://github.com/rmcpantoja/)\n",
        "- Decorado por: [Xx_Nessu_xX](https://fakeyou.com/profile/Xx_Nessu_xX)"
      ],
      "metadata": {
        "id": "A3qnewJMt_pt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5AEGy-ffkfIN"
      },
      "outputs": [],
      "source": [
        "#@markdown # <font color=\"pink\"> **Instalar software.** 📦\n",
        "#@markdown ---\n",
        "#@markdown #### <font color=\"orange\">**Importante: Reinicia el entorno de ejecución al terminar de ejecutarse esta celda. Luego, continúa a la siguiente celda.**\n",
        "%cd /content\n",
        "!git clone https://github.com/rmcpantoja/vits.git\n",
        "%cd vits\n",
        "!pip install Cython librosa==0.8.0 matplotlib numpy phonemizer num2words scipy tensorboard Unidecode torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -U\n",
        "#%cd vits\n",
        "%cd monotonic_align\n",
        "!mkdir monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "!apt-get install espeak-ng\n",
        "%cd ..\n",
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **Descargar e Iniciar el modelo TTS.** 💾\n",
        "#@markdown ---\n",
        "#@markdown Pon el ID de tu modelo.  <font color=\"orange\">**(Archivo G_0)**\n",
        "%cd /content/vits\n",
        "model_drive_id = \"Pon la id del archivo g_0 aqu\\xED\" #@param{type: \"string\"}\n",
        "!gdown '{model_drive_id}' -O /content/vits/pretrained.pth\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Audio, Markdown, Javascript\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import commons\n",
        "import utils\n",
        "from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
        "from models import SynthesizerTrn\n",
        "from text.symbols import symbols\n",
        "from text import text_to_sequence\n",
        "\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "def get_text(text, hps):\n",
        "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
        "    if hps.data.add_blank:\n",
        "        text_norm = commons.intersperse(text_norm, 0)\n",
        "    text_norm = torch.LongTensor(text_norm).cuda()\n",
        "    return text_norm\n",
        "\n",
        "hps = utils.get_hparams_from_file(\"./configs/base_es_singlespeaker_22k.json\")\n",
        "net_g = SynthesizerTrn(\n",
        "    len(symbols),\n",
        "    hps.data.filter_length // 2 + 1,\n",
        "    hps.train.segment_size // hps.data.hop_length,\n",
        "    **hps.model).cuda()\n",
        "_ = net_g.eval()\n",
        "\n",
        "_ = utils.load_checkpoint(\"pretrained.pth\", net_g, None)\n",
        "\n",
        "def run_tts(text, rate = 1, noise_s = 0.667, noise_scale_w = 0.8, auto_play=True):\n",
        "    stn_tst = get_text(text, hps)\n",
        "    with torch.no_grad():\n",
        "        x_tst = stn_tst.cuda().unsqueeze(0)\n",
        "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
        "        audio = net_g.infer(x_tst, x_tst_lengths, noise_scale=noise_s, noise_scale_w=noise_scale_w, length_scale=rate)[0][0,0].data.cpu().float().numpy()\n",
        "    display(Markdown(f\"{text}\"))\n",
        "    display(Audio(audio, rate=hps.data.sampling_rate, autoplay=auto_play))\n",
        "speed_slider = widgets.FloatSlider(\n",
        "    value=1,\n",
        "    min=0.25,\n",
        "    max=4,\n",
        "    step=0.1,\n",
        "    description=\"Escala de velocidad:\",\n",
        "    orientation='horizontal',\n",
        ")\n",
        "noise_scale_slider = widgets.FloatSlider(\n",
        "    value=0.667,\n",
        "    min=0.25,\n",
        "    max=4,\n",
        "    step=0.1,\n",
        "    description=\"Escala de resonancia de los fonemas:\",\n",
        "    orientation='horizontal',\n",
        ")\n",
        "noise_scale_w_slider = widgets.FloatSlider(\n",
        "    value=1,\n",
        "    min=0.25,\n",
        "    max=4,\n",
        "    step=0.1,\n",
        "    description=\"Noise scale w:\",\n",
        "    orientation='horizontal',\n",
        ")\n",
        "play = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description=\"Auto reproducir:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "text_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder=\"Introduce tu texto aquí:\",\n",
        "    description=\"Texto para sintetizar\",\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "synthesize_button = widgets.Button(\n",
        "    description=\"Sintetizar\",\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip=\"Presionando este botón se comenzará a sintetizar el texto.\",\n",
        "    icon='check'\n",
        ")\n",
        "def on_synthesize_button_clicked(b):\n",
        "    text = text_input.value\n",
        "    rate = speed_slider.value\n",
        "    noise_scale = noise_scale_slider.value\n",
        "    noise_scale_w = noise_scale_w_slider.value\n",
        "    auto_play = play.value\n",
        "    run_tts(text, rate, noise_scale, noise_scale_w, auto_play)\n",
        "\n",
        "synthesize_button.on_click(on_synthesize_button_clicked)\n",
        "display(text_input)\n",
        "display(speed_slider)\n",
        "display(noise_scale_slider)\n",
        "display(noise_scale_w_slider)\n",
        "display(play)\n",
        "display(synthesize_button)"
      ],
      "metadata": {
        "id": "St9mqH6ik5CF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
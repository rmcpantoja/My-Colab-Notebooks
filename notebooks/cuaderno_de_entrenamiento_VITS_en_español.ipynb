{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/cuaderno_de_entrenamiento_VITS_en_espa%C3%B1ol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><font color=\"pink\" size=\"+2\"> Cuaderno para entrenamiento de [VITS TTS](https://github.com/jaywalnut310/vits)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Cuaderno y soporte para el Espa√±ol desarrollados por [rmcpantoja](https://github.com/rmcpantoja/), en colaboraci√≥n con [Mixomo](https://github.com/Mixomo/efficient-vits-finetuning-Spanish-support-WIP-).\n",
        "\n",
        "## Cr√©ditos:\n",
        "* Decorador del cuaderno: [Xx_Nessu_xX](https://fakeyou.com/profile/Xx_Nessu_xX)\n",
        "\n",
        "## Citas:\n",
        "* VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech. (Jaehyeon Kim, Jungil Kong, y Juhee Son, 2021): https://arxiv.org/abs/2106.06103"
      ],
      "metadata": {
        "id": "E1XlFGnCea3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"pink\"> üîß ***Primeros pasos*** üîß"
      ],
      "metadata": {
        "id": "KsSF9JIGfwmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **Google Colab Anti-Disconnect.** üîå\n",
        "#@markdown ---\n",
        "#@markdown #### Evita la desconexi√≥n autom√°tica. Aun as√≠, se desconectar√° despu√©s de <font color=\"orange\">**6 a 12 horas**</font>.\n",
        "\n",
        "import IPython\n",
        "js_code = '''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Sz4mLEYFYvqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **Comprobar GPU asignada.** üëÅÔ∏è\n",
        "!nvidia-smi\n",
        "#@markdown ---\n",
        "#@markdown #### Una GPU con mayor capacidad puede llevar a mayor velocidad de entrenamiento. Por defecto, tendr√°s una <font color=\"orange\">**Tesla T4**</font>."
      ],
      "metadata": {
        "cellView": "form",
        "id": "oeDHAaq2f2lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **Montar Google Drive.** üìÇ\n",
        "#@markdown ---\n",
        "#@markdown **Se necesita como m√≠nimo <font color=\"orange\">1 - 2 GB</font> de espacio libre.**\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VBqc70UggSGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **Instalar software.** üì¶\n",
        "#@markdown ---\n",
        "#@markdown En esta celda se instalar√° el sintetizador y sus componentes necesarios para ejecutar el entrenamiento. (Esto puede tomar un tiempo)\n",
        "\n",
        "#@markdown <font color=\"orange\">**Nota: por ahora, el fine-tuning/ajuste de tus datasets se entrenar√°n usando el modelo Ingl√©s de LJSpeech como base. Estamos en camino para modelos preentrenados en espa√±ol, por lo que podr√° mejorar la capacidad de entrenamiento. Entonces, necesitar√°s mucha cantidad de datos para que funcione decente.**\n",
        "%cd /content\n",
        "!git clone https://github.com/Mixomo/efficient-vits-finetuning-Spanish-support-WIP- vits\n",
        "%cd vits\n",
        "!cp /usr/local/cuda/lib64/libcudart.so.11.0 /usr/lib64-nvidia/libcudart.so.11.0\n",
        "# FOR ORIGINAL REPO:\n",
        "#!pip install Cython librosa==0.8.0 matplotlib==3.3.1 numpy phonemizer scipy==1.7.2 tensorboard Unidecode torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -U\n",
        "#FOR FINE-TUNE REPO:\n",
        "!pip install Cython librosa==0.9.1 matplotlib numpy scipy tensorboard unidecode protobuf tqdm phonemizer bitsandbytes wandb num2words\n",
        "%cd monotonic_align\n",
        "!mkdir monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "!sudo apt-get install espeak-ng\n",
        "%cd ..\n",
        "# descargar procesador JSON:\n",
        "!wget https://github.com/mikefarah/yq/releases/download/v4.29.2/yq_linux_amd64.tar.gz\n",
        "!tar -xvf yq_linux_amd64.tar.gz\n",
        "#actualizar gdown y descargar modelos preentrenados (ljspeech ingl√©s, espa√±ol pronto):\n",
        "!pip install --upgrade gdown\n",
        "import gdown\n",
        "gdown.download(\"https://drive.google.com/file/d/1T-u3OV49W6Lv3bDxh-EA63ALZKHqyy0t/view?usp=sharing\", \"/content/vits/pretrained/generator.pth\", quiet=False, fuzzy=True)\n",
        "gdown.download(\"https://drive.google.com/file/d/118ffn807Eqlu891qbNRQP7O9E0-aMPxM/view?usp=sharing\", \"/content/vits/pretrained/discriminator.pth\", quiet=False, fuzzy=True)\n",
        "# check bitsandbytes\n",
        "!python -m bitsandbytes\n",
        "# for dataset:\n",
        "!mkdir /content/vits/wavs"
      ],
      "metadata": {
        "id": "aBc8-Zp9hYhr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"pink\"> ü§ñ ***Entrenamiento.*** ü§ñ"
      ],
      "metadata": {
        "id": "NoxLXHjqlgUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **1. Extrae el conjunto de datos.** üì•\n",
        "#@markdown ---\n",
        "#@markdown <font color=\"orange\">**Importante: los audios deber√°n estar en formato wav, (22050hz, 16-bits, mono), y, para comodidad, enumerados. Ejemplo:**\n",
        "\n",
        "#@markdown * <font color=\"orange\">**1.wav**</font>\n",
        "#@markdown * <font color=\"orange\">**2.wav**</font>\n",
        "#@markdown * <font color=\"orange\">**3.wav**</font>\n",
        "#@markdown * <font color=\"orange\">**.....**</font>\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #### Ruta de audios. <font color=\"orange\">**(√âstos deber√°n estar en un archivo comprimido zip, sueltos.)**</font>\n",
        "wavs_path = \"/content/drive/MyDrive/wavs.zip\" #@param {type:\"string\"}\n",
        "!unzip -q \"{wavs_path}\" -d /content/vits/wavs"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5tA2Vmblh7W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **2. Subir y procesar la transcripci√≥n.** üìù\n",
        "#@markdown ---\n",
        "#@markdown <font color=\"orange\">**Importante: la transcripci√≥n significa escribir lo que dice el personaje en cada uno de los audios, y deber√° tener la siguiente estructura:**\n",
        "\n",
        "#@markdown * <font color=\"orange\">**wavs/1.wav|Cuando los espa√±oles llegaron a Am√©rica se encontraron con monta√±as imponentes, r√≠os inmensos, abor√≠genes desconocidos, feroces algunos, muy apacibles otros.**</font>\n",
        "#@markdown * <font color=\"orange\">**wavs/2.wav|Al influjo de los elementos de naturaleza tan grandiosa y de sus extraordinarios habitantes, los conquistadores empezaron a tejer una serie de mitos y leyendas para justificar su existencia.**</font>\n",
        "#@markdown * <font color=\"orange\">**wavs/3.wav|La de las amazonas es una de ellas, y cuenta que hace mucho tiempo, la tribu de los Worisiana se instal√≥ a orillas del poderoso r√≠o-mar.**</font>\n",
        "#@markdown * <font color=\"orange\">**...**</font>\n",
        "\n",
        "#@markdown Y as√≠ sucesibamente. Adem√°s, la transcripci√≥n deber√° tener un <font color=\"orange\">**formato .txt (UTF-8 sin BOM)**</font>\n",
        "\n",
        "from google.colab import files\n",
        "import random\n",
        "%cd /content/vits/filelists\n",
        "!rm /content/vits/filelists/list.txt\n",
        "listfn, length = files.upload().popitem()\n",
        "if listfn != \"list.txt\":\n",
        "  !mv \"$listfn\" list.txt\n",
        "%cd ..\n",
        "print(\"¬°Transcripci√≥n subida! dibidiendo la lista en entrenamiento y validaci√≥n...\")\n",
        "with open(\"filelists/list.txt\", encoding=\"utf-8\") as f:\n",
        "  original = f.read().split('\\n')\n",
        "\n",
        "ratio = 0.01\n",
        "def split_data(data, ratio):\n",
        "  train_index = list(range(len(data)))\n",
        "  val_index = []\n",
        "  while len(val_index) < ratio * len(train_index):\n",
        "    val_index.append(train_index.pop(random.randint(0, len(train_index)-1)))\n",
        "  return [data[i] for i in train_index], [data[i] for i in val_index]\n",
        "\n",
        "train, val = split_data(original, ratio)\n",
        "\n",
        "with open(\"filelists/list.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write('\\n'.join(train))\n",
        "\n",
        "with open(\"filelists/list_val.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write('\\n'.join(val))\n",
        "print(\"¬°Completado! Procesando el texto a fonemas...\")\n",
        "!python preprocess.py --filelists \"filelists/list.txt\" \"filelists/list_val.txt\" --text_cleaners \"spanish_cleaners\"\n",
        "print(\"¬°Todo listo!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OzmsRRbkjV3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **3. Configuraci√≥n.** üß∞\n",
        "#@markdown ---\n",
        "config_path = \"configs/ljs_base.json\"\n",
        "#@markdown #### Nombre deseado para el modelo:\n",
        "model_name = \"Nombre\" #@param {type:\"string\"}\n",
        "!./yq_linux_amd64 -i '.data.name = \"{model_name}\"' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### Carpeta de salida: (No se recomienda cambiar)\n",
        "output_path = \"/content/drive/MyDrive/colab/vits\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Frecuencia de muestreo: (Opcional)\n",
        "sample_rate = \"22050\" #@param [\"22050\", \"32000\", \"44100\"]\n",
        "!./yq_linux_amd64 -i '.data.sampling_rate = {sample_rate}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### √âpocas de entrenamiento:\n",
        "train_epochs = 200 #@param {type:\"integer\"}\n",
        "!./yq_linux_amd64 -i '.train.epochs = {train_epochs}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "##@markdown #### Tasa de aprendizaje: (No se recomienda cambiar)\n",
        "#learning_rate = 2e-4\n",
        "#!./yq_linux_amd64 -i '.train.learning_rate = {learning_rate}' \"{config_path}\"\n",
        "##@markdown ---\n",
        "#@markdown #### Tama√±o del lote:\n",
        "batch_size = 12 #@param {type:\"integer\"}\n",
        "!./yq_linux_amd64 -i '.train.batch_size = {batch_size}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### ¬øResumir wandb?\n",
        "wandb_resume = False #@param {type:\"boolean\"}\n",
        "if wandb_resume:\n",
        "    resume = \"true\"\n",
        "else:\n",
        "    resume = \"false\"\n",
        "!./yq_linux_amd64 -i '.train.wandb_resume = {resume}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "# train and val:\n",
        "!./yq_linux_amd64 -i '.data.training_files = \"filelists/list.txt.cleaned\"' \"{config_path}\"\n",
        "!./yq_linux_amd64 -i '.data.validation_files = \"filelists/list_val.txt.cleaned\"' \"{config_path}\"\n",
        "# cleaner:\n",
        "!./yq_linux_amd64 -i '.data.text_cleaners = ['spanish_cleaners']' \"{config_path}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "c7VEnSBqwzJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **4. Ejecutar la extensi√≥n TensorBoard.** üìà\n",
        "#@markdown ---\n",
        "import os\n",
        "if not os.path.exists(\"/content/drive/MyDrive/colab/vits\"):\n",
        "    os.makedirs(\"/content/drive/MyDrive/colab/vits\")\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"{output_path}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "FDKthiBqlkXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"pink\"> **5. Comenzar el entrenamiento.** üèãÔ∏è‚Äç‚ôÇÔ∏è\n",
        "#@markdown ---\n",
        "#@markdown <font color=\"orange\">**Importante: si entrenas desde cero, recuerda eliminar los respaldos anteriores de modelos (si se encuentran) para evitar mayor consumo de espacio.**\n",
        "\n",
        "!python train.py --config \"{config_path}\" --model \"{model_name}\" --path \"{output_path}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "MzzezyVbl2mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"pink\">üéß ***¬øCurioso por escuchar c√≥mo suena el modelo?*** üéß\n",
        "\n",
        "### ¬°Prueba el cuaderno de s√≠ntesis [aqu√≠](https://colab.research.google.com/drive/1mlqngf8t6NUMAD35A8dimMEe2_sXdYAL)!"
      ],
      "metadata": {
        "id": "7TH_6HQAZbMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"pink\"> üìì ***Cuadernos relacionados o de inter√©s.*** üìì\n",
        "\n",
        "* [Cuaderno completo de SoftVC VITS Singing Voice Conversion (entrenamiento+inferencia)](https://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/Cuaderno_completo_So_Vits_SVC_en_espa%C3%B1ol.ipynb)"
      ],
      "metadata": {
        "id": "3aBWltkkdFDG"
      }
    }
  ]
}
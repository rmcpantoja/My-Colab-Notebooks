{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["-ognVXccZjDg","_TKXe-ttOtJh"],"authorship_tag":"ABX9TyMr0qpH44ZB2eKDqdakT4th"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# `Forward Tacotron` training notebook\n","This notebook has been developed by [rmcpantoja](https://github.com/rmcpantoja)\n","## credits:\n","\n","* [as-ideas/ForwardTacotron repository](https://github.com/as-ideas/ForwardTacotron).\n","\n","\n","### important!:\n","\n","* This notebook is still under development, so some features may not be available. For example the vocoder training and alignment features. The notebook will be constantly updated and I will remove this notice as soon as it is finished and testing is complete.\n","* For now, this notebook is not optimal for training with small datasets. I'm planning to retrain ljspeech dataset for tacotron. After that, small datasets can be trained.\n","\n","\n","last update: 2022/11/13"],"metadata":{"id":"uoBeS27om4F-"}},{"cell_type":"code","source":["#@markdown ### check allocated GPU\n","#@markdown ---\n","#@markdown You need at least one tesla t4, since the training process will take longer. If you have a GPU like k80, go to the menu bar and select runtime-disconnect and remove runtime.\n","#@markdown * You can also run this notebook without a GPU (not recommended) by disabling hardware acceleration in the notebook settings.\n","#@markdown * However, keep in mind that the total time required to train will be much longer than on a GPU, and could take up to weeks to complete.\n","!nvidia-smi -L"],"metadata":{"cellView":"form","id":"8XpLMaC8om1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### mount google drive\n","#@markdown ---\n","#@markdown This is very important to store the checkpoints and preprocessed datasets that Forward Tacotron will be able to work with. However, some important notes:\n","#@markdown * It's important that you verify your storage space in [Drive](http://drive.google.com/). Depending on the size of the dataset, you need to calculate a larger amount of available space.\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"cellView":"form","id":"GoIuX2WsqEHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ## install process\n","#@markdown ---\n","#@markdown This will install the synthesizer and other important dependencies.\n","%cd /content\n","import os\n","from os.path import exists\n","if (not os.path.exists(\"/content/ForwardTacotron\")):\n","  print(\"Cloning repository...\")\n","  !git clone https://github.com/as-ideas/ForwardTacotron\n","else:\n","  print(\"The working repository already exists. Skipping...\")\n","# pip:\n","!pip install numba librosa pyworld phonemizer==2.2.2 webrtcvad PyYAML dataclasses soundfile scipy tensorboard matplotlib unidecode inflect\n","#!pip install git+https://github.com/wkentaro/gdown.git\n","%cd /content/ForwardTacotron\n","#apt:\n","!apt install espeak-ng\n","!wget https://github.com/mikefarah/yq/releases/download/v4.29.2/yq_linux_amd64.tar.gz\n","!tar -xvf yq_linux_amd64.tar.gz\n","!mv /content/ForwardTacotron/yq_linux_amd64 /content/ForwardTacotron/yq\n","#!bash install-man-page.sh\n","print(\"ready\")"],"metadata":{"cellView":"form","id":"kNbm8T4apkae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### settings\n","#@markdown These are some options with which we can modify settings related to data and training.\n","#@markdown ---\n","#@markdown #### desired name for the TTS model\n","tts_model_id = \"myvoice\" #@param {type:\"string\"}\n","!./yq -i '.tts_model_id = \"{tts_model_id}\"' \"config.yaml\"\n","#@markdown ---\n","#@markdown #### Desired name for the vocoder (if you are going to train one)\n","voc_model_id = \"myvocoder\" #@param {type:\"string\"}\n","!./yq -i '.voc_model_id = \"{voc_model_id}\"' \"config.yaml\"\n","#@markdown ---\n","#@markdown #### the model type to be trained on this dataset\n","tts_model = \"forward_tacotron\" #@param [\"forward_tacotron\", \"fast_pitch\"]\n","!./yq -i '.tts_model = \"{tts_model}\"' \"config.yaml\"\n","#@markdown ---\n","#@markdown #### output directory\n","#@markdown (it is recommended to save it in drive)\n","data_path = \"/content/drive/MyDrive/ForwardTacotron\" #@param {type:\"string\"}\n","if not os.path.exists(data_path):\n","  os.makedirs(data_path)\n","  os.makedirs(data_path+\"/data\")\n","!./yq -i '.data_path = \"{data_path}/data/\"' \"config.yaml\"\n","#@markdown ---\n","#@markdown #### number of validation (not recommended to change)\n","n_val = 200 #@param {type:\"integer\"}\n","!./yq -i '.preprocessing.n_val = {n_val}' \"config.yaml\"\n","#@markdown ---\n","#@markdown #### Choose the language variation in which you have this dataset\n","#@markdown Here is a table to choose the desired language code:\n","\n","#@markdown Code  | Language \n","\n","#@markdown en-029  | English (Caribbean)\n","\n","#@markdown en-gb  | English (Great Britain)\n","\n","#@markdown en-gb-scotland  | English (Scotland)\n","\n","#@markdown en-gb-x-gbclan  | English (Lancaster)\n","\n","#@markdown en-gb-x-gbcwmd  | English (West Midlands)\n","\n","#@markdown en-gb-x-rp  | English (Received Pronunciation)\n","\n","#@markdown en-us  | English (America)\n","\n","language = 'en-us' #@param [\"en-029\", \"en-gb\", \"en-gb-scotland\", \"en-gb-x-gbclan\", \"en-gb-x-gbcwmd\", \"en-gb-x-rp\", \"en-us\"]\n","!./yq -i '.preprocessing.language = \"{language}\"' \"config.yaml\"\n","#@markdown ---\n","#@markdown #### Step interval to generate model training signals\n","#@markdown Here we can configure how many steps figures, images, visuals and audio will be generated, that is, the progress of the training that can be seen in tensorboard (later).\n","plot_every = 1000 #@param {type:\"integer\"}\n","!./yq -i '.tacotron.training.plot_every = {plot_every}' \"config.yaml\"\n","!./yq -i '.forward_tacotron.training.plot_every = {plot_every}' \"config.yaml\"\n","!./yq -i '.fast_pitch.training.plot_every = {plot_every}' \"config.yaml\"\n","#@markdown ---"],"metadata":{"cellView":"form","id":"JDfQsoTXqHnq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## working with the dataset\n","\n","You can skip these cells if you have already preprocessed a dataset for the first time and want to train it on the last saved checkpoint. Otherwise, expand this section and read the instructions for each cell."],"metadata":{"id":"-ognVXccZjDg"}},{"cell_type":"code","source":["import zipfile\n","import os\n","import os.path\n","#@markdown ### dataset preprocessing\n","#@markdown ---\n","#@markdown This will extract the dataset, do a few tweaks to the transcripts, and finally process it. Mel and pitch datasets will be created, these will be part of the training process.\n","#@markdown * Note: If you are going to preprocess larger datasets, it is recommended to have more space available on your drive.\n","#@markdown ---\n","#@markdown #### wavs path (zip file)\n","wavs_path = \"/content/drive/MyDrive/Wavs_m.zip\" #@param {type:\"string\"}\n","#@markdown ---\n","#@markdown #### transcription path (*.txt or *.csv)\n","list_path = \"/content/drive/MyDrive/list_m.txt\" #@param {type:\"string\"}\n","list_filename = os.path.basename(list_path).split('/')[-1]\n","#@markdown ---\n","%cd /content/ForwardTacotron\n","!mkdir /content/ForwardTacotron/wavs\n","if zipfile.is_zipfile(wavs_path):\n","  !unzip -j \"$wavs_path\" -d /content/ForwardTacotron/wavs\n","else:\n","  print(\"Warning: the wav path is not a compressed file.\")\n","\n","if not os.path.exists(list_path):\n","  raise Exception(\"Error: Transcript file does not exist, please try again.\")\n","else:\n","  !cp $list_path /content/ForwardTacotron\n","if list_path.endswith('.txt'):\n","  print(\"Fixing transcript...\")\n","  !mv /content/ForwardTacotron/$list_filename /content/ForwardTacotron/list.csv\n","  !sed -i -- 's,.wav|,|,g' \"/content/ForwardTacotron/list.csv\"\n","  !sed -i -- 's,wavs/,,g' \"/content/ForwardTacotron/list.csv\"\n","print(\"Running preprocess...\")\n","!python preprocess.py --path /content/ForwardTacotron\n","print(\"Ready\")"],"metadata":{"cellView":"form","id":"DeVSn6JGtLwW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Caution! You should run this cell if you have a dataset in your forward tacotron and want to train another. The contents will be deleted."],"metadata":{"id":"_TKXe-ttOtJh"}},{"cell_type":"code","source":["#@markdown ### remove the current dataset (if it exists)\n","#@markdown ---\n","#@markdown Since the datasets are in the working folder, you may need to train another dataset. If so, run this cell to do so.\n","# dataset\n","!rm -rf /content/ForwardTacotron/*.csv\n","!rm -rf /content/ForwardTacotron/*.wav\n","!rm -rf /content/ForwardTacotron/*.zip\n","# preprocessed:\n","!rm -rf /content/ForwardTacotron/*.npy\n","!rm -rf /content/ForwardTacotron/data/*"],"metadata":{"cellView":"form","id":"iSGxbKxXLuGS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train!\n","This series of steps will require time to achieve a stable training and after hours, and sometimes a few days, to obtain the final results. Please, I suggest carefully reading the indications of each of the cells.\n","\n","### to do:\n","* An option if the user wants to train a vocoder.\n","* Make a retrain of LJSpeech pretrained model to be able to train smaller datasets. This can last up to 2-3 weeks.\n","  * When this process is finished, allow to be downloaded in the training section and make a selection box with pre-trained model.\n","\n","These features will be added soon."],"metadata":{"id":"z18_1tmByBTQ"}},{"cell_type":"code","source":["#@markdown ### Apply patches\n","#@markdown ---\n","#@markdown Before continuing, I recommend running this cell to patch the path functions.\n","#@markdown * This patch fixes the save path of the models that are generated, and configures them to be saved in the {forwardTacotron folder on your [drive](http://drive.google.com/).\n","#@markdown * By skipping the creation of this patch the generated models will be saved in the root folder of the project instead of the ForwardTacotron folder created in the drive.\n","%%writefile /content/ForwardTacotron/utils/paths.py\n","import os\n","from pathlib import Path\n","\n","\n","class Paths:\n","    \"\"\"Manages and configures the paths used by WaveRNN, Tacotron, and the data.\"\"\"\n","    def __init__(self, data_path, voc_id, tts_id):\n","        self.base = Path(__file__).parent.parent.expanduser().resolve()\n","\n","        # Data Paths\n","        self.data = Path(data_path).expanduser().resolve()\n","        self.quant = self.data/'quant'\n","        self.mel = self.data/'mel'\n","        self.gta = self.data/'gta'\n","        self.alg = self.data/'alg'\n","        self.raw_pitch = self.data/'raw_pitch'\n","        self.phon_pitch = self.data/'phon_pitch'\n","        self.phon_energy = self.data/'phon_energy'\n","\n","        self.model_output = self.base / 'model_output'\n","\n","        self.voc_checkpoints = self.data/'../checkpoints'/f'{voc_id}.wavernn'\n","        self.voc_top_k = self.voc_checkpoints/'top_k_models'\n","        self.voc_log = self.voc_checkpoints/'logs'\n","\n","        self.taco_checkpoints = self.data/ '../checkpoints' / f'{tts_id}.tacotron'\n","        self.taco_log = self.taco_checkpoints / 'logs'\n","\n","        self.forward_checkpoints = self.data/'../checkpoints'/f'{tts_id}.forward'\n","        self.forward_log = self.forward_checkpoints/'logs'\n","\n","        self.create_paths()\n","\n","    def create_paths(self):\n","        os.makedirs(self.data, exist_ok=True)\n","        os.makedirs(self.quant, exist_ok=True)\n","        os.makedirs(self.mel, exist_ok=True)\n","        os.makedirs(self.gta, exist_ok=True)\n","        os.makedirs(self.alg, exist_ok=True)\n","        os.makedirs(self.raw_pitch, exist_ok=True)\n","        os.makedirs(self.phon_pitch, exist_ok=True)\n","        os.makedirs(self.phon_energy, exist_ok=True)\n","        os.makedirs(self.voc_checkpoints, exist_ok=True)\n","        os.makedirs(self.voc_top_k, exist_ok=True)\n","        os.makedirs(self.taco_checkpoints, exist_ok=True)\n","        os.makedirs(self.forward_checkpoints, exist_ok=True)\n","\n","    def get_tts_named_weights(self, name):\n","        \"\"\"Gets the path for the weights in a named tts checkpoint.\"\"\"\n","        return self.taco_checkpoints / f'{name}_weights.pyt'\n","\n","    def get_tts_named_optim(self, name):\n","        \"\"\"Gets the path for the optimizer state in a named tts checkpoint.\"\"\"\n","        return self.taco_checkpoints / f'{name}_optim.pyt'\n","\n","    def get_voc_named_weights(self, name):\n","        \"\"\"Gets the path for the weights in a named voc checkpoint.\"\"\"\n","        return self.voc_checkpoints/f'{name}_weights.pyt'\n","\n","    def get_voc_named_optim(self, name):\n","        \"\"\"Gets the path for the optimizer state in a named voc checkpoint.\"\"\"\n","        return self.voc_checkpoints/f'{name}_optim.pyt'\n","\n","\n"],"metadata":{"cellView":"form","id":"cwfRdebZceU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### Run tensorboard\n","#@markdown --\n","#@markdown The tensorboard is used to visualize the model training process. Note that if you want to visualize this, you can go to the **audio**, **image** or **scalars** tabs.\n","%load_ext tensorboard\n","%tensorboard --logdir \"checkpoints\"\n","import tensorflow as tf\n","import datetime"],"metadata":{"cellView":"form","id":"SXYKGmDHus0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### Train 1: Tacotron\n","#@markdown ---\n","!python train_tacotron.py"],"metadata":{"cellView":"form","id":"CoKJIkYvy_4o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### Train 2: Forward Tacotron\n","#@markdown ---\n","#@markdown This will train the final model for forward tacotron, taking into account the pre-processed dataset along with the alignments and pitch conditions and the generated tacotron model that we worked on in the previous cells.\n","#@markdown * We will have a division of two models, 150k steps each.\n","#@markdown * Please note that care will be taken into account based on the tacotron model. If you are training with few files due to bad attention (we can tell this when training starts) there is a problem in the dataset, so please try to review it, fix what is necessary, add more data or revise carefully the Tensorboard.\n","!python train_forward.py"],"metadata":{"cellView":"form","id":"Ox7B0EUizBgc"},"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-ognVXccZjDg",
        "_TKXe-ttOtJh"
      ],
      "authorship_tag": "ABX9TyMoGJ06l3pIM5a+63nI8CEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/ForwardTacotron_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìì`Forward Tacotron` training notebook. üìì\n",
        "\n",
        "*Version: 1.0.*\n",
        "\n",
        "---\n",
        "\n",
        "This notebook has been developed by [rmcpantoja](https://github.com/rmcpantoja)\n",
        "\n",
        "# ‚úâÔ∏è Thanks:\n",
        "\n",
        "* To [Xx_Nessu_xX](https://fakeyou.com/profile/Xx_Nessu_xX) for the design and notebook fixes.\n",
        "* To [Exink](http://github.com/exink) for help in the development of this notebook.\n",
        "\n",
        "\n",
        "## üìùcredits:\n",
        "\n",
        "* [as-ideas/ForwardTacotron repository](https://github.com/as-ideas/ForwardTacotron).\n",
        "\n",
        "*last update: 2023/03/26*"
      ],
      "metadata": {
        "id": "uoBeS27om4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üëÅÔ∏ècheck allocated GPU.\n",
        "#@markdown ---\n",
        "#@markdown You need at least one tesla t4, since the training process will take longer. If you have a GPU like k80, go to the menu bar and select runtime-disconnect and remove runtime.\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8XpLMaC8om1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üìÅmount google drive.\n",
        "#@markdown ---\n",
        "#@markdown This is very important to store the checkpoints and preprocessed datasets that Forward Tacotron will be able to work with. However, some important notes:\n",
        "#@markdown * It's important that you verify your storage space in [Drive](http://drive.google.com/). Depending on the size of the dataset, you need to calculate a larger amount of available space.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GoIuX2WsqEHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## üíªinstall process.\n",
        "#@markdown ---\n",
        "#@markdown This will install the synthesizer and other important dependencies.\n",
        "\n",
        "#@markdown * Nota: reinicia el entorno de ejecuci√≥n si se te solicita y, a continuaci√≥n, ejecuta esta celda nuevamente y despu√©s prosigue m√°s adelante sin problemas.\n",
        "\n",
        "%cd /content\n",
        "import os\n",
        "from os.path import exists\n",
        "if (not os.path.exists(\"/content/ForwardTacotron\")):\n",
        "  !git clone https://github.com/as-ideas/ForwardTacotron\n",
        "# pip:\n",
        "!pip install numba librosa pyworld phonemizer webrtcvad PyYAML dataclasses soundfile scipy tensorboard matplotlib unidecode inflect resemblyzer==0.1.1-dev pandas\n",
        "!pip install --upgrade gdown\n",
        "%cd /content/ForwardTacotron\n",
        "!rm -r .git/\n",
        "#apt:\n",
        "!apt install espeak-ng\n",
        "print(\"ready\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kNbm8T4apkae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üóÇÔ∏è project setup."
      ],
      "metadata": {
        "id": "Nsz7MI6nCJHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ForwardTacotron\n",
        "#@markdown ### üîßsettings wizard.\n",
        "\n",
        "#@markdown These are some options with which we can modify settings related to data and training. You can run this cell to manage it.\n",
        "\n",
        "#@markdown ---\n",
        "# imports:\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import Markdown\n",
        "from utils.files import read_config, save_config\n",
        "\n",
        "# interface:\n",
        "model_type  = widgets.Dropdown(\n",
        "    options=['Single speaker', 'Multiple speakers'],\n",
        "    value='Single speaker',\n",
        "    description='Model variant:',\n",
        ")\n",
        "\n",
        "tts_model_id = widgets.Text(\n",
        "    value='ExampleTTS',\n",
        "    description='desired name for the model:',\n",
        ")\n",
        "tts_model = widgets.ToggleButtons(\n",
        "    options=['forward_tacotron', 'multi_forward_tacotron', 'fast_pitch'],\n",
        "    description='Model to train:',\n",
        ")\n",
        "continue_training = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Continue a training?',\n",
        ")\n",
        "\n",
        "preprocess_path = widgets.Text(\n",
        "    value='/content/drive/MyDrive/ForwardTacotron/EjemploTTS/dataset_preprocessed.zip',\n",
        "    description='Preprocessing path ffrom Drive (if enabled)',\n",
        "    disabled=True\n",
        ")\n",
        "\n",
        "custom_save_dir = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Save checkpoints and preprocessing to a custom path? (recomended)',\n",
        ")\n",
        "save_dir = widgets.Text(\n",
        "    value='/content/drive/MyDrive/ForwardTacotron/EjemploTTS',\n",
        "    description='If it's this checkbox on, where do you want to save it?',\n",
        "    disabled=True\n",
        ")\n",
        "sample_rate = widgets.IntText(\n",
        "    value=22050,\n",
        "    min=16000,\n",
        "    max=48000,\n",
        "    step=1000,\n",
        "    description='Sample rate: (Opcional)',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "metafile_format = widgets.Dropdown(\n",
        "    options=['ljspeech', 'ljspeech_multi', 'pandas', 'vctk'],\n",
        "    value='ljspeech',\n",
        "    description='Transcript format:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "n_val = widgets.IntText(\n",
        "    value=10,\n",
        "    min=1,\n",
        "    max=200,\n",
        "    step=1,\n",
        "    description='Number of validations (You can adjust it according to the size of your dataset):',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "language = widgets.Dropdown(\n",
        "    options=['en-029', 'en-gb', 'en-gb-scotland', 'en-gb-x-gbclan', 'en-gb-x-gbcwmd', 'en-gb-x-rp', 'en-us'],\n",
        "    value='en-us',\n",
        "    description='Dataset language variation:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "plot_every = widgets.IntText(\n",
        "    value=1000,\n",
        "    min=500,\n",
        "    max=5000,\n",
        "    step=1000,\n",
        "    description='Step interval to generate model training samples (tensorboard):',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "applyBTN = widgets.Button(\n",
        "    description='apply settings',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "def on_continue_training_change(change):\n",
        "    if change['new']:\n",
        "        preprocess_path.disabled = False\n",
        "    else:\n",
        "        preprocess_path.disabled = True\n",
        "\n",
        "def on_custom_save_dir_change(change):\n",
        "    if change['new']:\n",
        "        save_dir.disabled = False\n",
        "    else:\n",
        "        save_dir.disabled = True\n",
        "\n",
        "def check_config(model_type):\n",
        "    if model_type == \"Single speaker\":\n",
        "        config_path = \"configs/singlespeaker.yaml\"\n",
        "    elif model_type == \"Multiple speakers\":\n",
        "        config_path = \"configs/multispeaker.yaml\"\n",
        "    else:\n",
        "        raise Exception(\"Tipo de modelo no soportado. Actualmente, puedes elegir entre Single speaker o varios\")\n",
        "    return config_path\n",
        "\n",
        "def save_settings(b):\n",
        "    tts_id = tts_model_id.value\n",
        "    display(Markdown(f\"\"\"\n",
        "# Settings summary:\n",
        "\n",
        "* Model type: {model_type.value}.\n",
        "* TTS Models Name: {tts_id}.\n",
        "* TTS model to use: {tts_model.value}.\n",
        "* Continue a training: {continue_training.value}.\n",
        "* Use a custom save directory for the models: {custom_save_dir.value}.\n",
        "* Sample rate: {sample_rate.value}.\n",
        "* Transcript format: {metafile_format.value}.\n",
        "* Number of validations: {n_val.value}.\n",
        "* Language: {language.value}\n",
        "* Generation of training samples every {plot_every.value} steps.\n",
        "\n",
        "If there's something you need to fix, you can adjust and apply the settings again.\n",
        "    \"\"\"))\n",
        "    config_path = check_config(model_type.value)\n",
        "    config = read_config(config_path)\n",
        "    config['tts_model_id'] = tts_id\n",
        "    if tts_model.value == \"multi_forward_tacotron\" and model_type.value == \"Single speaker\":\n",
        "        raise Exception(\"The multi_forward_tacotron model is only supported on multispeaker models.\")\n",
        "    config['tts_model'] = tts_model.value\n",
        "    if continue_training.value:\n",
        "        !unzip -q \"{preprocess_path.value}\" -d /content/ForwardTacotron\n",
        "    if custom_save_dir.value:\n",
        "        if not os.path.exists(save_dir.value):\n",
        "            os.makedirs(save_dir.value)\n",
        "    else:\n",
        "        print(\"Warning! Changes will not be saved, only in the local project folder.\")\n",
        "        save_dir.value = \"/content/ForwardTacotron\"\n",
        "    config['dsp']['sample_rate'] = sample_rate.value\n",
        "    config['dsp']['vad_sample_rate'] = sample_rate.value\n",
        "    if metafile_format.value == \"ljspeech\" and model_type.value == \"Multiple speakers\":\n",
        "        raise Exception(\"The ljspeech format is supported only on Single speaker models.\")\n",
        "    elif metafile_format.value == \"ljspeech_multi\" or metafile_format.value == \"pandas\" or metafile_format.value == \"vctk\":\n",
        "        if model_type.value == \"Single speaker\":\n",
        "            raise Exception(\"Neither the ljspeech_multi model, pandas nor vctk do not support Single speaker models.\")\n",
        "    config['preprocessing']['metafile_format'] = metafile_format.value\n",
        "    config['preprocessing']['n_val'] = n_val.value\n",
        "    config['preprocessing']['language'] = language.value\n",
        "    # reduce workers in dur extraction:\n",
        "    config['duration_extraction']['num_workers'] = 2\n",
        "    # Tacotron singlespeaker (80k steps):\n",
        "    if model_type == \"Single speaker\":\n",
        "        config['tacotron']['training']['schedule'] = ['5,  1e-3,  10_000,  32', '3,   1e-4,  20_000,  16', '2,   1e-4,  30_000,  8', '1,   1e-4,  40_000,  8', '5,  1e-3,  50_000,  32', '3,   1e-4,  60_000,  16', '2,   1e-4,  70_000,  8', '1,   1e-4,  80_000,  8']\n",
        "    # todo: multispeaker pretrained models.\n",
        "    # plot:\n",
        "    config['tacotron']['training']['plot_every'] = plot_every.value\n",
        "    if model_type.value == \"Multiple speakers\":\n",
        "        config['multi_forward_tacotron']['training']['plot_every'] = plot_every.value\n",
        "    else:\n",
        "        config['forward_tacotron']['training']['plot_every'] = plot_every.value\n",
        "        config['fast_pitch']['training']['plot_every'] = plot_every.value\n",
        "    # Manage pretrained models:\n",
        "    if model_type.value == \"Single speaker\":\n",
        "        if not continue_training.value:\n",
        "            if not os.path.exists(save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron\"):\n",
        "                os.makedirs(save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron\")\n",
        "            print(f\"Download the pretrained model in: {save_dir.value}/checkpoints/{tts_id}.tacotron\")\n",
        "            !gdown -q 1-_p_NZ3Njhrx03E2VVeyBxR-1kKo3YQp -O \"{save_dir.value}/checkpoints/{tts_id}.tacotron/latest_model.pt\"\n",
        "        else:\n",
        "            print(f\"Training will resume in: {save_dir.value}/checkpoints/{tts_id}.tacotron\")\n",
        "    else:\n",
        "        print(f\"Warning! Currently, there's no pre-trained model for {model_type.value}. We're probably working on it. If you want, you can submit a pull request on GitHub. A model will be trained from scratch.\")\n",
        "    # check checkpoints:\n",
        "    if continue_training.value:\n",
        "        if custom_save_dir.value:\n",
        "            if not os.path.exists(save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron/latest_model.pt\"):\n",
        "                raise Exception(\"It sounds like you're trying to continue a training. However, I can't find the model in the specified path. Please fix it.\"+save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron/latest_model.pt\")\n",
        "    # phoneme singlespeaker:\n",
        "    config['preprocessing']['use_phonemes'] = True\n",
        "    # attention:\n",
        "    if model_type.value == \"Multiple speakers\":\n",
        "        config['multi_forward_tacotron']['training']['filter_attention'] = True\n",
        "        config['multi_forward_tacotron']['training']['min_attention_sharpness'] = 0.5\n",
        "        config['multi_forward_tacotron']['training']['min_attention_alignment'] = 0.75\n",
        "    else:\n",
        "        config['forward_tacotron']['training']['filter_attention'] = True\n",
        "        config['forward_tacotron']['training']['min_attention_sharpness'] = 0.5\n",
        "        config['forward_tacotron']['training']['min_attention_alignment'] = 0.75\n",
        "    save_config(config, config_path)\n",
        "    print(\"Configuration saved successfully!\")\n",
        "    return config_path\n",
        "\n",
        "continue_training.observe(on_continue_training_change, names='value')\n",
        "custom_save_dir.observe(on_custom_save_dir_change, names='value')\n",
        "\n",
        "display(model_type )\n",
        "display(tts_model_id)\n",
        "display(tts_model)\n",
        "display(Markdown(\"The `multi_forward_tacotron` option is supported for multi-speaker models only.\"))\n",
        "display(continue_training)\n",
        "display(preprocess_path)\n",
        "display(custom_save_dir)\n",
        "display(save_dir)\n",
        "display(sample_rate)\n",
        "display(metafile_format)\n",
        "display(Markdown(\"The `ljspeech` format is the only one used for single-speaker models.\"))\n",
        "display(n_val)\n",
        "display(language)\n",
        "display(Markdown('''\n",
        "Here's a table to choose the desired language code:\n",
        "\n",
        "| Code | Language |\n",
        "|:---:|:---:|:---:|\n",
        "|en-029|English (Caribbean)|\n",
        "|en-gb|English (Great Britain)|\n",
        "|en-gb-scotland|English (Scotland)|\n",
        "|en-gb-x-gbclan|English (Lancaster)|\n",
        "|en-gb-x-gbcwmd|English (West Midlands)|\n",
        "|en-gb-x-rp|English (Received Pronunciation)|\n",
        "|en-us|English (America)|\n",
        "'''))\n",
        "display(plot_every)\n",
        "display(Markdown(\"Note: this setting will apply to all models: Tacotron, Forward_tacotron, multi_forward_tacotron (if training with multiple speakers), and FastPitch.\"))\n",
        "display(applyBTN)\n",
        "applyBTN.on_click(save_settings)\n",
        "config_path = check_config(model_type.value)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JDfQsoTXqHnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### ‚öôÔ∏èApply patches according to settings.\n",
        "#@markdown ---\n",
        "#@markdown Before continuing, it's recommended to run this cell to patch the paths where the models are saved. By skipping this cell, these will be saved to the root folder of the project instead of the custom save directory (if you have the corresponding box checked).\n",
        "\n",
        "tts_id = tts_model_id.value\n",
        "voc_id = tts_model_id.value+\"_voc\"\n",
        "name = \"test\"\n",
        "\n",
        "print(\"applying patch...\")\n",
        "with open('/content/ForwardTacotron/utils/paths.py', 'w') as f:\n",
        "  f.write('''\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class Paths:\n",
        "    \"\"\"Manages and configures the paths used by WaveRNN, Tacotron, and the data.\"\"\"\n",
        "    def __init__(self, data_path, tts_id):\n",
        "\n",
        "        # directories\n",
        "        self.base = Path(__file__).parent.parent.expanduser().resolve()\n",
        "        self.data = Path(data_path).expanduser().resolve()\n",
        "        self.quant = self.data/'quant'\n",
        "        self.mel = self.data/'mel'\n",
        "        self.gta = self.data/'gta'\n",
        "        self.att_pred = self.data/'att_pred'\n",
        "        self.alg = self.data/'alg'\n",
        "        self.speaker_emb = self.data/'speaker_emb'\n",
        "        self.mean_speaker_emb = self.data/'mean_speaker_emb'\n",
        "        self.raw_pitch = self.data/'raw_pitch'\n",
        "        self.phon_pitch = self.data/'phon_pitch'\n",
        "        self.phon_energy = self.data/'phon_energy'\n",
        "        self.model_output = self.base / 'model_output'\n",
        "        self.save_dir = Path(\"'''+save_dir.value+'''\").expanduser().resolve()\n",
        "        self.taco_checkpoints = self.save_dir/'checkpoints/'''+tts_id+'''.tacotron'\n",
        "        self.taco_log = self.taco_checkpoints / 'logs'\n",
        "        self.forward_checkpoints = self.save_dir/'checkpoints/'''+tts_id+'''.forward'\n",
        "        self.forward_log = self.forward_checkpoints/'logs'\n",
        "\n",
        "        # pickle objects\n",
        "        self.train_dataset = self.data / 'train_dataset.pkl'\n",
        "        self.val_dataset = self.data / 'val_dataset.pkl'\n",
        "        self.text_dict = self.data / 'text_dict.pkl'\n",
        "        self.speaker_dict = self.data / 'speaker_dict.pkl'\n",
        "        self.att_score_dict = self.data / 'att_score_dict.pkl'\n",
        "        # future:\n",
        "        self.duration_stats = self.data / 'duration_stats.pkl'\n",
        "\n",
        "        self.create_paths()\n",
        "\n",
        "    def create_paths(self):\n",
        "        os.makedirs(self.data, exist_ok=True)\n",
        "        os.makedirs(self.quant, exist_ok=True)\n",
        "        os.makedirs(self.mel, exist_ok=True)\n",
        "        os.makedirs(self.gta, exist_ok=True)\n",
        "        os.makedirs(self.alg, exist_ok=True)\n",
        "        os.makedirs(self.speaker_emb, exist_ok=True)\n",
        "        os.makedirs(self.mean_speaker_emb, exist_ok=True)\n",
        "        os.makedirs(self.att_pred, exist_ok=True)\n",
        "        os.makedirs(self.raw_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_energy, exist_ok=True)\n",
        "        os.makedirs(self.taco_checkpoints, exist_ok=True)\n",
        "        os.makedirs(self.forward_checkpoints, exist_ok=True)\n",
        "\n",
        "    def get_tts_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_weights.pyt'\n",
        "\n",
        "    def get_tts_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_optim.pyt'\n",
        "\n",
        "    def get_voc_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_weights.pyt'\n",
        "\n",
        "    def get_voc_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_optim.pyt'\n",
        "''')\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xxenz38ajQ4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## working with the dataset.\n",
        "\n",
        "**You can skip these cells if you have already preprocessed a dataset for the first time and want to train it on the last saved checkpoint. Otherwise, expand this section and read the instructions for each cell.**"
      ],
      "metadata": {
        "id": "-ognVXccZjDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import os.path\n",
        "#@markdown ### üíædataset preprocessing.\n",
        "#@markdown ---\n",
        "#@markdown * Note: If you are going to preprocess larger datasets, it is recommended to have more space available on your drive.\n",
        "#@markdown ---\n",
        "#@markdown #### üîäwavs path (zip file):\n",
        "wavs_path = \"/content/drive/MyDrive/Wavs_m.zip\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### ‚úçÔ∏èTranscription Path: (By default metadata.csv)\n",
        "list_path = \"/content/drive/MyDrive/list.csv\" #@param {type:\"string\"}\n",
        "list_filename = os.path.basename(list_path).split('/')[-1]\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "!mkdir dataset\n",
        "%cd dataset\n",
        "!mkdir wavs\n",
        "if zipfile.is_zipfile(wavs_path):\n",
        "  !unzip -j \"$wavs_path\" -d /content/dataset/wavs\n",
        "else:\n",
        "  print(\"Warning: the wavs path is not a compressed file.\")\n",
        "if list_path.endswith('.txt'):\n",
        "  raise Exception(\"The transcript format should be in csv extension.\")\n",
        "if not os.path.exists(list_path):\n",
        "  raise Exception(\"Error: Transcript file does not exist, please try again.\")\n",
        "else:\n",
        "  !cp $list_path /content/ForwardTacotron\n",
        "%cd /content/ForwardTacotron\n",
        "print(\"Running preprocess...\")\n",
        "!python preprocess.py --path /content/dataset --config \"{config_path}\" --metafile \"{list_filename}\"\n",
        "if custom_save_dir.value:\n",
        "  print(\"Backing up preprocessed data...\")\n",
        "  if model_type == \"multiple speakers\":\":\n",
        "    !zip -r \"{save_dir.value}/dataset_preprocessed.zip\" data_multisspeaker\n",
        "  elif model_type == \"Single speaker\":\n",
        "    !zip -r \"{save_dir.value}/dataset_preprocessed.zip\" configs data\n",
        "  else:\n",
        "    raise Exception(\"The model type is not recognized. Remember that you can only choose between a single speaker or multiple speakers.\")\n",
        "  print(\"The preprocessing has been compressed. This is useful for resuming a training next to checkpoints. The configs will not be saved, so remember the configuration settings from this session as it will be useful to return to it at any time.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DeVSn6JGtLwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='red'>‚ö†Ô∏è Caution!</font> You should run this cell if you have a dataset in your forward tacotron and want to train another. The contents will be deleted. ‚ö†Ô∏è </font>"
      ],
      "metadata": {
        "id": "_TKXe-ttOtJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### <font color='red'>Remove the current dataset (if it exists):\n",
        "#@markdown ---\n",
        "#@markdown Since the datasets are in the working folder, you may need to train another dataset. If so, run this cell to do so.\n",
        "# dataset\n",
        "!rm -rf /content/ForwardTacotron/dataset\n",
        "# preprocessed:\n",
        "!rm -rf /content/ForwardTacotron/data/*"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iSGxbKxXLuGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèãÔ∏èTrain!\n",
        "These steps will require time to achieve a stable training and after hours, and sometimes a few days, to obtain the final results. Please, I suggest carefully reading the indications of each of the cells."
      ],
      "metadata": {
        "id": "z18_1tmByBTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üìàRun tensorboard extension.\n",
        "#@markdown --\n",
        "#@markdown The tensorboard is used to visualize the model training process. Note that if you want to visualize this, you can go to the **audio**, **image** or **scalars** tabs.\n",
        "%load_ext tensorboard\n",
        "print(f\"directory: {save_dir.value}/checkpoints\")\n",
        "%tensorboard --logdir \"{save_dir.value}/checkpoints\"\n",
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SXYKGmDHus0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üé§Train 1: Tacotron.\n",
        "#@markdown ---\n",
        "#@markdown A point to take into account is the training division.\n",
        "#@markdown * The model will be trained between a total of 40k steps. By default, backups are saved every 10k steps, so we should be concerned about storage. ___(Instead, you can delete the old backups. Also, the one that really matters and is used is the latest_model.pt checkpoint that is saved most often.)___\n",
        "#@markdown * Likewise, this training complies with a schedule which will apply different parameters.\n",
        "#@markdown\n",
        "#@markdown Let's train!\n",
        "\n",
        "!python train_tacotron.py --config \"{config_path}\"\n",
        "# include att score, pitch, att, aligments and more:\n",
        "if custom_save_dir.value:\n",
        "  print(\"But first, backing up the work that's just been done...\")\n",
        "  if model_type.value == \"Multiple speakers\":\":\n",
        "    !zip \"{save_dir.value}/dataset_preprocessed.zip\" data_multisspeaker\n",
        "  elif model_type.value == \"Single speaker\":\n",
        "    !zip \"$save_dir/dataset_preprocessed.zip\" data\n",
        "  else:\n",
        "    raise Exception(\"The model type is not recognized. Remember that you can only choose between a single speaker or multiple speakers.\")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CoKJIkYvy_4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üöÄTrain 2: Forward Tacotron.\n",
        "#@markdown ---\n",
        "#@markdown This will train the final model for Forward Tacotron, taking into account the work done previously.\n",
        "#@markdown * It will also follow a schedule. By default, it trains up to 300k steps, but it can work with less.\n",
        "#@markdown * Please note that care will be taken into account based on the tacotron model. If you are training with few files due to bad attention (we can tell this when training starts) there is a problem in the dataset, so please try to review it, fix what is necessary, add more data or revise carefully the Tensorboard.\n",
        "#@markdown * You can adjust the batch size if you are out of memory during the session here.\n",
        "batch_size = 24 #@param {type:\"integer\"}\n",
        "# check TTS_model:\n",
        "config_path = check_config(model_type.value)\n",
        "config = read_config(config_path)\n",
        "if tts_model.value == \"forward_tacotron\":\n",
        "    config['forward_tacotron']['training']['schedule'] = ['5e-5,  150_000,  '+str(batch_size), '1e-5,  300_000,  '+str(batch_size)]\n",
        "elif tts_model.value == \"multi_forward_tacotron\":\n",
        "    config['multi_forward_tacotron']['training']['schedule'] = ['5e-5,  500_000,  '+str(batch_size), '1e-5,  600_000,  '+str(batch_size)]\n",
        "elif tts_model.value == \"fast_pitch\":\n",
        "    config['fast_pitch']['training']['schedule'] = ['1e-5,  5_000,  '+str(batch_size), '5e-5,  100_000,  '+str(batch_size), '2e-5,  300_000,  '+str(batch_size)]\n",
        "else:\n",
        "    raise Exception(f\"This TTS model isn't supported: {tts_model.value}.\")\n",
        "save_config(config, config_path)\n",
        "#@markdown ---\n",
        "\n",
        "!python train_forward.py --config \"{config_path}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ox7B0EUizBgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßçHave you finished training for today?üè†üö∂\n",
        "üîäTest the model in the synthesis notebook by clicking [here.](https://colab.research.google.com/drive/1yHdMGB5H6JG44TAN5BNcv7f95beN3qYZ)"
      ],
      "metadata": {
        "id": "FasTazpjLTAz"
      }
    }
  ]
}
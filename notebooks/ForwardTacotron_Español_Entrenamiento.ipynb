{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-ognVXccZjDg",
        "_TKXe-ttOtJh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/ForwardTacotron_Espa%C3%B1ol_Entrenamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìì Cuaderno de entrenamiento de `Forward Tacotron` (En espa√±ol). üìì\n",
        "\n",
        "*Versi√≥n: 1.1.*\n",
        "\n",
        "---\n",
        "\n",
        "Este cuaderno ha sido desarrollado por [rmcpantoja](https://github.com/rmcpantoja).\n",
        "\n",
        "# ‚úâÔ∏è Agradecimientos:\n",
        "\n",
        "* A [Xx_Nessu_xX](https://fakeyou.com/profile/Xx_Nessu_xX) por el dise√±o y correcci√≥n del cuaderno.\n",
        "* A [Exink](http://github.com/exink) por la ayuda en el desarrollo de este cuaderno.\n",
        "\n",
        "## üìù Cr√©ditos:\n",
        "\n",
        "* Repositorio de [as-ideas/ForwardTacotron](https://github.com/as-ideas/ForwardTacotron).\n",
        "\n",
        "*√öltima actualizaci√≥n: 02/04/2023*"
      ],
      "metadata": {
        "id": "uoBeS27om4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üëÅÔ∏èComprobar la GPU asignada.\n",
        "#@markdown ---\n",
        "#@markdown Necesitas una `Tesla T4` como m√≠nimo. Si tienes una GPU como `K80`, ve a la barra de men√∫s y selecciona Entorno de ejecuci√≥n > Desconectarse y eliminar entorno de ejecuci√≥n.\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8XpLMaC8om1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üìÅMontar Google drive.\n",
        "#@markdown ---\n",
        "#@markdown Esto es muy importante para almacenar los puntos de control y los conjuntos de datos procesados con los que Forward Tacotron podr√° trabajar. Sin embargo, algunas notas importantes:\n",
        "#@markdown * Es importante que verifiques tu espacio de almacenamiento en [Drive](http://drive.google.com/). De acuerdo al tama√±o del dataset, necesitas calcular una mayor cantidad de espacio disponible.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GoIuX2WsqEHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## üíªIniciar el proceso de instalaci√≥n.\n",
        "#@markdown ---\n",
        "#@markdown Esto instalar√° el sintetizador y otras dependencias importantes.\n",
        "\n",
        "#@markdown * Nota: reinicia el entorno de ejecuci√≥n si se te solicita y, a continuaci√≥n, ejecuta esta celda nuevamente y despu√©s prosigue m√°s adelante sin problemas.\n",
        "\n",
        "#@markdown #### <font color=orange>¬øQuieres utilizar la versi√≥n 3.2 de ForwardTacotron?\n",
        "\n",
        "#@markdown La versi√≥n 3.2 es la √∫ltima que s√≥lo contiene soporte para un √∫nico hablante.\n",
        "only_singlespeaker_version = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "import os\n",
        "from os.path import exists\n",
        "if (not os.path.exists(\"/content/ForwardTacotron\")):\n",
        "  !git clone https://github.com/as-ideas/ForwardTacotron\n",
        "# pip:\n",
        "if only_singlespeaker_version:\n",
        "  !pip install numba librosa pyworld phonemizer webrtcvad PyYAML dataclasses soundfile scipy tensorboard matplotlib unidecode inflect\n",
        "else:\n",
        "  !pip install numba librosa==0.8 pyworld phonemizer webrtcvad PyYAML dataclasses soundfile scipy tensorboard matplotlib unidecode inflect resemblyzer==0.1.1-dev pandas tabulate\n",
        "!pip install --upgrade gdown\n",
        "%cd /content/ForwardTacotron\n",
        "if only_singlespeaker_version:\n",
        "  !git checkout 632b453c6cb6d15dfe4dd168cd60c60e56731829\n",
        "!rm -r .git/\n",
        "#apt:\n",
        "!apt install espeak-ng\n",
        "print(\"Listo\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kNbm8T4apkae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üóÇÔ∏è Preparaci√≥n del proyecto."
      ],
      "metadata": {
        "id": "zacBLAngiO4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ForwardTacotron\n",
        "#@markdown ### üîßAsistente de configuraci√≥n.\n",
        "\n",
        "#@markdown Estas son algunas configuraciones con las que podremos modificar ajustes relacionados a datos y entrenamiento. Puedes ejecutar esta celda para administrarla.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "# imports:\n",
        "nimport os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import Markdown\n",
        "from utils.files import read_config, save_config\n",
        "\n",
        "# interface:\n",
        "model_type  = widgets.Dropdown(\n",
        "    options=['Un solo hablante', 'Un solo hablante (versi√≥n 3.2)', 'Varios hablantes'],\n",
        "    value='Un solo hablante (versi√≥n 3.2)',\n",
        "    description='Variante de modelo a usar:',\n",
        ")\n",
        "\n",
        "tts_model_id = widgets.Text(\n",
        "    value='EjemploTTS',\n",
        "    description='Nombre deseado para el modelo:',\n",
        ")\n",
        "tts_model = widgets.ToggleButtons(\n",
        "    options=['fast_pitch', 'multi_fast_pitch', 'forward_tacotron', 'multi_forward_tacotron'],\n",
        "    description='Modelo que se va a entrenar:',\n",
        ")\n",
        "continue_training = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='¬øContinuar un entrenamiento?',\n",
        ")\n",
        "\n",
        "preprocess_path = widgets.Text(\n",
        "    value='/content/drive/MyDrive/ForwardTacotron/EjemploTTS/dataset_preprocessed.zip',\n",
        "    description='Ubicaci√≥n del preprocesamiento en Drive (si est√° activado)',\n",
        "    disabled=True\n",
        ")\n",
        "\n",
        "custom_save_dir = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='¬øGuardar puntos de control y preprocesamiento en una ubicaci√≥n personalizada? (recomendado)',\n",
        ")\n",
        "save_dir = widgets.Text(\n",
        "    value='/content/drive/MyDrive/ForwardTacotron/EjemploTTS',\n",
        "    description='Si est√° activado, ¬ød√≥nde deseas guardarlo?',\n",
        "    disabled=True\n",
        ")\n",
        "sample_rate = widgets.IntText(\n",
        "    value=22050,\n",
        "    min=16000,\n",
        "    max=48000,\n",
        "    step=1000,\n",
        "    description='Frecuencia de muestreo: (Opcional)',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "metafile_format = widgets.Dropdown(\n",
        "    options=['ljspeech', 'ljspeech_multi', 'pandas', 'vctk'],\n",
        "    value='ljspeech',\n",
        "    description='Formato del archivo de transcripciones:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "n_val = widgets.IntText(\n",
        "    value=10,\n",
        "    min=1,\n",
        "    max=500,\n",
        "    step=1,\n",
        "    description='N√∫mero de validaciones (aj√∫stalo seg√∫n el tama√±o del conjunto de datos):',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "language = widgets.Dropdown(\n",
        "    options=['es', 'es-419'],\n",
        "    value='es',\n",
        "    description='Variaci√≥n de idioma del conjunto de datos:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "plot_every = widgets.IntText(\n",
        "    value=1000,\n",
        "    min=500,\n",
        "    max=10000,\n",
        "    step=1000,\n",
        "    description='Intervalo de pasos para generar se√±ales de entrenamiento del modelo (tensorboard):',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "toggle_advanced = widgets.ToggleButton(value=False, description='Mostrar opciones avanzadas')\n",
        "advanced_config = widgets.Accordion(children=[widgets.VBox([\n",
        "    widgets.HTML(value=\"<b>Cambia estos par√°metros si sabes lo que est√°s haciendo</b>\"),\n",
        "    widgets.Checkbox(value=True, description=\"Usar fonemas (recomendado)\"),\n",
        "    widgets.Dropdown(options=[\"librosa\", \"pyworld\"], value=\"pyworld\", description=\"Extractor de tono:\"),\n",
        "    widgets.IntSlider(min=1, max=16, value=12, description=\"N√∫mero de n√∫cleos a usar para la duraci√≥n: (si usas Colab gratuito, deber√°s establecer hasta dos n√∫cleos)\"),\n",
        "    widgets.Checkbox(value=True, description=\"Filtrar estad√≠sticas de duraci√≥n\"),\n",
        "    widgets.FloatText(value=0.5, description=\"Nitidez m√≠nima de la atenci√≥n:\"),\n",
        "    widgets.FloatText(value=0.95, description=\"Alineaci√≥n de atenci√≥n m√≠nima:\")\n",
        "    widgets.IntSlider(min=10, max=60, value=40, description=\"Duraci√≥n m√°xima para el filtro de duraciones:\"),\n",
        "    widgets.IntSlider(min=1, max=10, value=6, description=\"M√°ximo de consecutivos:\"),\n",
        "])])\n",
        "advanced_config.set_title(0, 'Configuraci√≥n avanzada')\n",
        "applyBTN = widgets.Button(\n",
        "    description='Aplicar configuraci√≥n',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "def check_dataset():\n",
        "    project_path = \"/content/ForwardTacotron/data/mel\"\n",
        "    num_files = len(os.listdir(project_path))\n",
        "    if num_files < 50:\n",
        "        raise Exception(f\"¬°El conjunto de datos es demasiado peque√±o! Se necesitan m√°s de {num_files} audios.\")\n",
        "    elif 50 <= num_files <= 125:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "def set_schedule(schedule):\n",
        "    if schedule == 1:\n",
        "        print(\"üì£Aviso: parece que tienes un conjunto de datos de menor tama√±o. Para estos casos deber√°s establecer el menor n√∫mero de validaciones posible para que funcione correctamente.\")\n",
        "        array = ['5,  1e-3,  10_000,  32', '3,   1e-4,  20_000,  16', '2,   1e-4,  30_000,  8', '1,   1e-4,  40_000,  8', '5,  1e-3,  50_000,  16', '3,   1e-4,  60_000,  8', '2,   1e-4,  70_000,  4', '1,   1e-4,  80_000,  4']\n",
        "    elif schedule == 2:\n",
        "        array = ['5,  1e-3,  10_000,  32', '3,   1e-4,  20_000,  16', '2,   1e-4,  30_000,  8', '1,   1e-4,  40_000,  8', '5,  1e-3,  50_000,  32', '3,   1e-4,  60_000,  16', '2,   1e-4,  70_000,  8', '1,   1e-4,  80_000,  8']\n",
        "    else:\n",
        "        raise Exception(f\"Invalid schedule: {schedule}\")\n",
        "    return array\n",
        "\n",
        "def on_continue_training_change(change):\n",
        "    if change['new']:\n",
        "        preprocess_path.disabled = False\n",
        "    else:\n",
        "        preprocess_path.disabled = True\n",
        "\n",
        "def on_custom_save_dir_change(change):\n",
        "    if change['new']:\n",
        "        save_dir.disabled = False\n",
        "    else:\n",
        "        save_dir.disabled = True\n",
        "\n",
        "def check_config(model_type):\n",
        "    if model_type == \"Un solo hablante\":\n",
        "        config_path = \"configs/singlespeaker.yaml\"\n",
        "    elif model_type == \"Varios hablantes\":\n",
        "        config_path = \"configs/multispeaker.yaml\"\n",
        "    elif model_type == \"Un solo hablante (versi√≥n 3.2)\" and only_singlespeaker_version:\n",
        "        config_path = \"config.yaml\"\n",
        "    else:\n",
        "        raise Exception(f\"Tipo de modelo no soportado. Actualmente, puedes elegir entre un solo hablante o varios. Si usas la versi√≥n 3.2, selecciona su opci√≥n correspondiente. Opci√≥n actual: {model_type}\")\n",
        "    return config_path\n",
        "\n",
        "def get_advanced_config(advanced_config):\n",
        "    if advanced_config.layout.display == '':\n",
        "        advanced_settings = True\n",
        "    else:\n",
        "        advanced_settings = False\n",
        "    return advanced_settings\n",
        "\n",
        "def toggle_advanced_config(change):\n",
        "    if change['new']:\n",
        "        advanced_config.layout.display = ''\n",
        "    else:\n",
        "        advanced_config.layout.display = 'none'\n",
        "\n",
        "def save_settings(b):\n",
        "    tts_id = tts_model_id.value\n",
        "    apply_advanced_config = get_advanced_config(advanced_config)\n",
        "    if apply_advanced_config:\n",
        "        use_phonemes = advanced_config.children[0].children[1].value\n",
        "        pitch_extractor = advanced_config.children[0].children[2].value\n",
        "        duration_num_workers = advanced_config.children[0].children[3].value\n",
        "        filter_duration_stats = advanced_config.children[0].children[4].value\n",
        "        min_attention_sharpness = advanced_config.children[0].children[5].value\n",
        "        min_attention_alignment = advanced_config.children[0].children[6].value\n",
        "        max_duration = advanced_config.children[0].children[7].value\n",
        "        max_consecutive_ones = advanced_config.children[0].children[8].value\n",
        "    else:\n",
        "        # Recommended settings for the data and colab:\n",
        "        use_phonemes = True\n",
        "        duration_num_workers = 2\n",
        "    display(Markdown(f\"\"\"\n",
        "# Resumen de la configuraci√≥n:\n",
        "\n",
        "* Tipo de modelo: {model_type.value}.\n",
        "* Nombre de modelos TTS: {tts_id}.\n",
        "* Modelo TTS a usar: {tts_model.value}.\n",
        "* Continuaci√≥n de un entrenamiento: {continue_training.value}.\n",
        "* Usar un directorio de guardado personalizado para los modelos: {custom_save_dir.value}.\n",
        "* Frecuencia de muestreo: {sample_rate.value}.\n",
        "* Formato de transcripciones: {metafile_format.value}.\n",
        "* N√∫mero de validaciones: {n_val.value}.\n",
        "* Idioma: {language.value}\n",
        "* Generaci√≥n de muestras del entrenamiento cada {plot_every.value} pasos.\n",
        "\n",
        "---\n",
        "\n",
        "    \"\"\"))\n",
        "    if apply_advanced_config:\n",
        "        display(Markdown(f\"\"\"\n",
        "## configuraci√≥n avanzada:\n",
        "\n",
        "* Usar fonemas: {use_phonemes}.\n",
        "* Extractor de tono: {pitch_extractor}.\n",
        "* N√∫mero de n√∫cleos para la extracci√≥n de duraciones: {duration_num_workers}.\n",
        "* Filtrar atenci√≥n (aplica para todos los modelos despu√©s de Tacotron): {filter_attention}.\n",
        "* Nitidez m√≠nima de atenci√≥n: {min_attention_sharpness}.\n",
        "* Atenci√≥n de alineaci√≥n m√≠nima: {min_attention_alignment}.\n",
        "\n",
        "Si hay algo en lo que consideres arreglar, puedes ajustar y aplicar nuevamente las configuraciones en cualquier momento sin volver a ejecutar la celda.\n",
        "        \"\"\"))\n",
        "    config_path = check_config(model_type.value)\n",
        "    config = read_config(config_path)\n",
        "    config['tts_model_id'] = tts_id\n",
        "    if tts_model.value == \"multi_forward_tacotron\" or tts_model.value == \"multi_fast_pitch\":\n",
        "        if model_type.value == \"Un solo hablante\":\n",
        "            raise Exception(\"Tanto el modelo multi_forward_tacotron como multi_fast_pitch solo est√°n soportados en modelos de varios hablantes.\")\n",
        "        elif tts_model.value == \"multi_forward_tacotron\" and only_singlespeaker_version:\n",
        "            raise Exception(f\"La versi√≥n 3.2 contiene modelos de un solo hablante; por lo tanto, no se soporta {model_type.value}.\")\n",
        "    config['tts_model'] = tts_model.value\n",
        "    if continue_training.value:\n",
        "        if os.path.exists(preprocess_path.value):\n",
        "            !unzip -q \"{preprocess_path.value}\" -d /content/ForwardTacotron\n",
        "        else:\n",
        "            raise Exception(f\"Ups, no puedo preparar las cosas para reanudad el entrenamiento porque no encuentro el archivo comprimido del procesado en {preprocess_path.value}. ¬øSeguro que est√° ah√≠?\")\n",
        "    if custom_save_dir.value:\n",
        "        if not os.path.exists(save_dir.value):\n",
        "            os.makedirs(save_dir.value)\n",
        "    else:\n",
        "        save_dir.value = \"/content/ForwardTacotron\"\n",
        "        print(f\"¬°Advertencia! Los avances no se guardar√°n, solo en la carpeta local del proyecto. Es decir, {save_dir.value}.\")\n",
        "    config['dsp']['sample_rate'] = sample_rate.value\n",
        "    #config['dsp']['vad_sample_rate'] = sample_rate.value\n",
        "    if not only_singlespeaker_version:\n",
        "        if metafile_format.value == \"ljspeech\" and model_type.value == \"Varios hablantes\":\n",
        "            raise Exception(\"El formato ljspeech es compatible solamente con los modelos de un solo hablante.\")\n",
        "        elif metafile_format.value == \"ljspeech_multi\" or metafile_format.value == \"pandas\" or metafile_format.value == \"vctk\":\n",
        "            if model_type.value == \"Un solo hablante\":\n",
        "                raise Exception(\"Ni el modelo ljspeech_multi, pandas ni vctk no son compatibles con modelos para un solo hablante.\")\n",
        "        config['preprocessing']['metafile_format'] = metafile_format.value\n",
        "    config['preprocessing']['n_val'] = n_val.value\n",
        "    config['preprocessing']['language'] = language.value\n",
        "    # set no cleaners:\n",
        "    cleaner_name = 'no_cleaners'\n",
        "    config['preprocessing']['cleaner_name'] = cleaner_name\n",
        "    # check dataset lenght:\n",
        "    schedule = check_dataset()\n",
        "    # Tacotron singlespeaker (80k steps):\n",
        "    if model_type.value == \"Un solo hablante\" or model_type.value == \"Un solo hablante (versi√≥n 3.2)\":\n",
        "        config['tacotron']['training']['schedule'] = set_schedule(schedule)\n",
        "    # todo: multispeaker pretrained models.\n",
        "    # plot:\n",
        "    config['tacotron']['training']['plot_every'] = plot_every.value\n",
        "    if model_type.value == \"Varios hablantes\":\n",
        "        config['multi_forward_tacotron']['training']['plot_every'] = plot_every.value\n",
        "        config['multi_fast_pitch']['training']['plot_every'] = plot_every.value\n",
        "    else:\n",
        "        config['forward_tacotron']['training']['plot_every'] = plot_every.value\n",
        "        config['fast_pitch']['training']['plot_every'] = plot_every.value\n",
        "    # Manage Spanish pretrained models:\n",
        "    if model_type.value == \"Un solo hablante (versi√≥n 3.2)\" and only_singlespeaker_version:\n",
        "        if not continue_training.value:\n",
        "            if not os.path.exists(save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron\"):\n",
        "                os.makedirs(save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron\")\n",
        "            print(f\"Descarga del modelo preentrenado en: {save_dir.value}/checkpoints/{tts_id}.tacotron\")\n",
        "            !gdown -q 1--8jkfZaFk2uDoqX-FE-CI4NUja5NR2V -O \"{save_dir.value}/checkpoints/{tts_id}.tacotron/latest_model.pt\"\n",
        "        else:\n",
        "            print(f\"Retomando entrenamiento en: {save_dir.value}/checkpoints/{tts_id}.tacotron\")\n",
        "    else:\n",
        "        print(f\"¬°Advertencia! Actualmente, no existe un modelo preentrenado para la edici√≥n {model_type.value}. Es probable que estemos trabajando en ello. Si deseas, puedes enviar una contribuci√≥n en la secci√≥n pull requests en GitHub ayudando con conjuntos de datos a entrenar o modelos preentrenados. Por el momento, se entrenar√° un modelo desde cero. Si esto es lo que quieres, es muy recomendable que la voz tenga horas de datos para que funcione correctamente.\")\n",
        "    # check checkpoints:\n",
        "    if continue_training.value:\n",
        "        if custom_save_dir.value:\n",
        "            if not os.path.exists(save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron/latest_model.pt\"):\n",
        "                raise Exception(\"Parece que est√°s intentando continuar un entrenamiento. Sin embargo, no encuentro el modelo en la ruta especificada. Por favor, arr√©glalo.\"+save_dir.value+\"/checkpoints/\"+tts_id+\".tacotron/latest_model.pt\")\n",
        "    if apply_advanced_config:\n",
        "        # phonemes:\n",
        "        config['preprocessing']['use_phonemes'] = use_phonemes\n",
        "        # pitch extractor:\n",
        "        config['preprocessing']['pitch_extractor'] = pitch_extractor\n",
        "        # Workers for dur extraction:\n",
        "        config['duration_extraction']['num_workers'] = duration_num_workers\n",
        "        # attention:\n",
        "        config[tts_model.value]['training']['filter']['filter_duration_stats'] = filter_duration_stats\n",
        "        config[tts_model.value]['training']['filter']['min_attention_sharpness'] = min_attention_sharpness\n",
        "        config[tts_model.value]['training']['filter']['min_attention_alignment'] = min_attention_alignment\n",
        "    else:\n",
        "        config['preprocessing']['use_phonemes'] = use_phonemes\n",
        "        config['duration_extraction']['num_workers'] = duration_num_workers\n",
        "    save_config(config, config_path)\n",
        "    print(\"¬°Configuraci√≥n guardada con √©xito!\")\n",
        "    return config\n",
        "\n",
        "continue_training.observe(on_continue_training_change, names='value')\n",
        "custom_save_dir.observe(on_custom_save_dir_change, names='value')\n",
        "\n",
        "display(model_type )\n",
        "display(tts_model_id)\n",
        "display(tts_model)\n",
        "display(Markdown(\"La opci√≥n multi_forward_tacotron est√° soportada solamente para modelos de varios hablantes.\"))\n",
        "display(continue_training)\n",
        "display(preprocess_path)\n",
        "display(custom_save_dir)\n",
        "display(save_dir)\n",
        "display(sample_rate)\n",
        "if only_singlespeaker_version:\n",
        "    display(Markdown(\"**Usando la versi√≥n 3.2. Por lo tanto, no se podr√° seleccionar formato de transcripciones.**\"))\n",
        "    metafile_format.disabled = True\n",
        "else:\n",
        "    display(metafile_format)\n",
        "    display(Markdown(\"El formato ljspeech es el √∫nico que se usa para modelos de un solo hablante.\"))\n",
        "display(n_val)\n",
        "display(language)\n",
        "display(Markdown('Tengamos en cuenta que \"es\" equivale a espa√±ol de espa√±a (recomendado) y \"es-419\" equivale al espa√±ol de latinoam√©rica.'))\n",
        "display(plot_every)\n",
        "display(Markdown(\"Nota: esta configuraci√≥n aplicar√° en todos los modelos: Tacotron, Forward_tacotron, multi_forward_tacotron o multi_fast_pitch (Si se entrena con varios hablantes), y FastPitch.\"))\n",
        "display(toggle_advanced)\n",
        "toggle_advanced.observe(toggle_advanced_config, names='value')\n",
        "display(advanced_config)\n",
        "advanced_config.layout.display = 'none'\n",
        "display(applyBTN)\n",
        "applyBTN.on_click(save_settings)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JDfQsoTXqHnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### ‚öôÔ∏èAplicar parches de acuerdo a la configuraci√≥n.\n",
        "#@markdown ---\n",
        "#@markdown Antes de continuar, es recomendable ejecutar esta celda para parchear las rutas donde se guardan los modelos. Saltando esta celda, estos se guardar√°n en la carpeta ra√≠z del proyecto en lugar de la carpeta de guardado personalizada (si tienes la casilla marcada correspondiente).\n",
        "\n",
        "tts_id = tts_model_id.value\n",
        "voc_id = tts_model_id.value+\"_voc\"\n",
        "name = \"test\"\n",
        "config_path = check_config(model_type.value)\n",
        "if only_singlespeaker_version:\n",
        "  print(\"Aplicando parche para la versi√≥n 3.2...\")\n",
        "  with open('/content/ForwardTacotron/utils/paths.py', 'w') as f:\n",
        "    f.write('''\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class Paths:\n",
        "    \"\"\"Manages and configures the paths used by WaveRNN, Tacotron, and the data.\"\"\"\n",
        "    def __init__(self, data_path, voc_id, tts_id):\n",
        "        self.base = Path(__file__).parent.parent.expanduser().resolve()\n",
        "\n",
        "        # Data Paths\n",
        "        self.data = Path(data_path).expanduser().resolve()\n",
        "        self.quant = self.data/'quant'\n",
        "        self.mel = self.data/'mel'\n",
        "        self.gta = self.data/'gta'\n",
        "        self.att_pred = self.data/'att_pred'\n",
        "        self.alg = self.data/'alg'\n",
        "        self.raw_pitch = self.data/'raw_pitch'\n",
        "        self.phon_pitch = self.data/'phon_pitch'\n",
        "        self.phon_energy = self.data/'phon_energy'\n",
        "        self.model_output = self.base / 'model_output'\n",
        "        self.save_dir = Path(\"'''+save_dir.value+'''\").expanduser().resolve()\n",
        "        self.voc_checkpoints = self.save_dir/'checkpoints/'''+voc_id+'''.wavernn'\n",
        "        self.voc_top_k = self.voc_checkpoints/'top_k_models'\n",
        "        self.voc_log = self.voc_checkpoints/'logs'\n",
        "        self.taco_checkpoints = self.save_dir/'checkpoints/'''+tts_id+'''.tacotron'\n",
        "        self.taco_log = self.taco_checkpoints / 'logs'\n",
        "        self.forward_checkpoints = self.save_dir/'checkpoints/'''+tts_id+'''.forward'\n",
        "        self.forward_log = self.forward_checkpoints/'logs'\n",
        "\n",
        "        self.create_paths()\n",
        "\n",
        "    def create_paths(self):\n",
        "        os.makedirs(self.data, exist_ok=True)\n",
        "        os.makedirs(self.quant, exist_ok=True)\n",
        "        os.makedirs(self.mel, exist_ok=True)\n",
        "        os.makedirs(self.gta, exist_ok=True)\n",
        "        os.makedirs(self.alg, exist_ok=True)\n",
        "        os.makedirs(self.att_pred, exist_ok=True)\n",
        "        os.makedirs(self.raw_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_energy, exist_ok=True)\n",
        "        os.makedirs(self.voc_checkpoints, exist_ok=True)\n",
        "        os.makedirs(self.voc_top_k, exist_ok=True)\n",
        "        os.makedirs(self.taco_checkpoints, exist_ok=True)\n",
        "        os.makedirs(self.forward_checkpoints, exist_ok=True)\n",
        "\n",
        "    def get_tts_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_weights.pyt'\n",
        "\n",
        "    def get_tts_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_optim.pyt'\n",
        "\n",
        "    def get_voc_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_weights.pyt'\n",
        "\n",
        "    def get_voc_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_optim.pyt'\n",
        "''')\n",
        "else:\n",
        "  print(\"Aplicando parche para la versi√≥n actual...\")\n",
        "  with open('/content/ForwardTacotron/utils/paths.py', 'w') as f:\n",
        "    f.write('''\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class Paths:\n",
        "    \"\"\"Manages and configures the paths used by WaveRNN, Tacotron, and the data.\"\"\"\n",
        "    def __init__(self, data_path, tts_id):\n",
        "\n",
        "        # directories\n",
        "        self.base = Path(__file__).parent.parent.expanduser().resolve()\n",
        "        self.data = Path(data_path).expanduser().resolve()\n",
        "        self.quant = self.data/'quant'\n",
        "        self.mel = self.data/'mel'\n",
        "        self.gta = self.data/'gta'\n",
        "        self.att_pred = self.data/'att_pred'\n",
        "        self.alg = self.data/'alg'\n",
        "        self.speaker_emb = self.data/'speaker_emb'\n",
        "        self.mean_speaker_emb = self.data/'mean_speaker_emb'\n",
        "        self.raw_pitch = self.data/'raw_pitch'\n",
        "        self.phon_pitch = self.data/'phon_pitch'\n",
        "        self.phon_energy = self.data/'phon_energy'\n",
        "        self.model_output = self.base / 'model_output'\n",
        "        self.save_dir = Path(\"'''+save_dir.value+'''\").expanduser().resolve()\n",
        "        self.taco_checkpoints = self.save_dir/'checkpoints/'''+tts_id+'''.tacotron'\n",
        "        self.taco_log = self.taco_checkpoints / 'logs'\n",
        "        self.forward_checkpoints = self.save_dir/'checkpoints/'''+tts_id+'''.forward'\n",
        "        self.forward_log = self.forward_checkpoints/'logs'\n",
        "\n",
        "        # pickle objects\n",
        "        self.train_dataset = self.data / 'train_dataset.pkl'\n",
        "        self.val_dataset = self.data / 'val_dataset.pkl'\n",
        "        self.text_dict = self.data / 'text_dict.pkl'\n",
        "        self.speaker_dict = self.data / 'speaker_dict.pkl'\n",
        "        self.att_score_dict = self.data / 'att_score_dict.pkl'\n",
        "        # future:\n",
        "        self.duration_stats = self.data / 'duration_stats.pkl'\n",
        "\n",
        "        self.create_paths()\n",
        "\n",
        "    def create_paths(self):\n",
        "        os.makedirs(self.data, exist_ok=True)\n",
        "        os.makedirs(self.quant, exist_ok=True)\n",
        "        os.makedirs(self.mel, exist_ok=True)\n",
        "        os.makedirs(self.gta, exist_ok=True)\n",
        "        os.makedirs(self.alg, exist_ok=True)\n",
        "        os.makedirs(self.speaker_emb, exist_ok=True)\n",
        "        os.makedirs(self.mean_speaker_emb, exist_ok=True)\n",
        "        os.makedirs(self.att_pred, exist_ok=True)\n",
        "        os.makedirs(self.raw_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_energy, exist_ok=True)\n",
        "        os.makedirs(self.taco_checkpoints, exist_ok=True)\n",
        "        os.makedirs(self.forward_checkpoints, exist_ok=True)\n",
        "\n",
        "    def get_tts_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_weights.pyt'\n",
        "\n",
        "    def get_tts_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_optim.pyt'\n",
        "\n",
        "    def get_voc_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_weights.pyt'\n",
        "\n",
        "    def get_voc_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_optim.pyt'\n",
        "''')\n",
        "print(\"¬°Listo!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KARSAWk5y7kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajando con el conjunto de datos.\n",
        "\n",
        "**Puedes saltarte estas celdas si ya pre-procesaste un dataset por primera vez y quieres entrenarlo en el √∫ltimo punto de control que se haya guardado. De lo contrario, expande esta secci√≥n y lee las instrucciones de cada celda.**"
      ],
      "metadata": {
        "id": "-ognVXccZjDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import os.path\n",
        "#@markdown ### üíæProcesamiento del conjuntos de datos.\n",
        "#@markdown ---\n",
        "#@markdown * Nota: si vas a preprocesar conjuntos de datos de mayor tama√±o, se recomienda tener m√°s espacio disponible en drive.\n",
        "#@markdown ---\n",
        "#@markdown #### üîäRuta de los audios. Ellos deber√°n almacenarse en un archivo .zip:\n",
        "wavs_path = \"/content/drive/MyDrive/wavs.zip\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### ‚úçÔ∏èRuta de transcripci√≥n: (Por defecto metadata.csv)\n",
        "list_path = \"/content/drive/MyDrive/list.csv\" #@param {type:\"string\"}\n",
        "list_filename = os.path.basename(list_path).split('/')[-1]\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "!mkdir dataset\n",
        "%cd dataset\n",
        "!mkdir wavs\n",
        "if zipfile.is_zipfile(wavs_path):\n",
        "  !unzip -j \"$wavs_path\" -d /content/dataset/wavs\n",
        "else:\n",
        "  raise Exception(\"La ruta de audios especificada no es un archivo comprimido.\")\n",
        "if list_path.endswith('.txt'):\n",
        "  raise Exception(\"El formato de la transcripci√≥n deber√° estar en formato csv.\")\n",
        "\n",
        "if not os.path.exists(list_path):\n",
        "  raise Exception(\"Error: el archivo de transcripci√≥n no existe, int√©ntelo de nuevo por favor.\")\n",
        "!cp $list_path /content/dataset\n",
        "%cd /content/ForwardTacotron\n",
        "print(\"Ejecutando procesamiento...\")\n",
        "if only_singlespeaker_version:\n",
        "  !python preprocess.py --path /content/dataset\n",
        "else:\n",
        "  !python preprocess.py --path /content/dataset --config \"{config_path}\" --metafile \"{list_filename}\"\n",
        "if custom_save_dir.value:\n",
        "  print(\"Respaldando preprocesamiento...\")\n",
        "  if model_type.value == \"Varios hablantes\":\n",
        "    !zip -r \"{save_dir.value}/dataset_preprocessed.zip\" data_multisspeaker\n",
        "  elif model_type.value == \"Un solo hablante\" or model_type.value == \"Un solo hablante (versi√≥n 3.2)\":\n",
        "    !zip -r \"{save_dir.value}/dataset_preprocessed.zip\" data\n",
        "  else:\n",
        "    raise Exception(\"No se reconoce el tipo de modelo. Recuerda que solo puedes elegir entre un solo hablante o varios.\")\n",
        "  print(\"El preprocesamiento se ha comprimido. Esto es √∫til para reanudar un entrenamiento junto a los puntos de control. Las configuraciones no se guardar√°n, as√≠ que recuerda los ajustes de configuraciones de esta sesi√≥n ya que te ser√° √∫til para retomarlo en cualquier momento.\")"
      ],
      "metadata": {
        "id": "DeVSn6JGtLwW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='red'>‚ö†Ô∏è ¬°Precauci√≥n! Debes ejecutar esta celda si tienes un conjunto de datos en tu Forward Tacotron y quieres entrenar otro. Los contenidos se borrar√°n. ‚ö†Ô∏è </font>"
      ],
      "metadata": {
        "id": "_TKXe-ttOtJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### <font color='red'>Borrar el conjunto de datos actual (si existe)\n",
        "#@markdown ---\n",
        "#@markdown Debido a que los datasets se encuentran en la carpeta de trabajo, es posible que necesites entrenar otro datasetp. Si es as√≠, ejecuta esta celda para hacerlo.\n",
        "# conjunto de datos\n",
        "!rm -rf /content/ForwardTacotron/dataset\n",
        "# preprocesado:\n",
        "!rm -rf /content/ForwardTacotron/data/*"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iSGxbKxXLuGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèãÔ∏è¬°A entrenar!\n",
        "Esta serie de pasos requerir√°n de tiempo para conseguir un entrenamiento estable y tras horas, y a veces algunos d√≠as, obtener los resultados finales. Por favor, sugiero leer atentamente las indicaciones de cada una de las celdas."
      ],
      "metadata": {
        "id": "BXhho463mSwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üìàEjecutar la extensi√≥n Tensorboard.\n",
        "#@markdown ---\n",
        "#@markdown El tensorboard sirve para visualizar el proceso de entrenamiento del modelo. Ten en cuenta que si quieres visualizar esto, puedes ir a las pesta√±as **audio**, **image** o **scalars**.\n",
        "%load_ext tensorboard\n",
        "print(f\"Directorio: {save_dir.value}/checkpoints\")\n",
        "%tensorboard --logdir \"{save_dir.value}/checkpoints\"\n",
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SXYKGmDHus0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üé§Entrenamiento 1: Tacotron.\n",
        "#@markdown ---\n",
        "#@markdown Un punto muy a tomar en cuenta es la divisi√≥n del entrenamiento.\n",
        "#@markdown * El modelo se entrenar√° entre un total de 40k pasos. De forma predeterminada, los respaldos se guardan cada 10k pasos, por lo que deber√≠amos preocuparnos por el almacenamiento. ___(En cambio, puedes borrar los respaldos antiguos. Igualmente, el que realmente importa y se usa es el latest_model que se guarda m√°s a menudo).___\n",
        "#@markdown * Asimismo, este entrenamiento cumple un cronograma el cual se aplicar√°n par√°metros diferentes.\n",
        "#@markdown\n",
        "#@markdown Sin m√°s, ¬°a entrenar!.\n",
        "if only_singlespeaker_version:\n",
        "  !python train_tacotron.py\n",
        "else:\n",
        "  !python train_tacotron.py --config \"{config_path}\"\n",
        "# include att score, pitch, att, aligments and more:\n",
        "if custom_save_dir.value:\n",
        "  print(\"Pero antes, respaldando el trabajo que se acaba de hacer...\")\n",
        "  if model_type.value == \"Varios hablantes:\":\n",
        "    !zip \"{save_dir.value}/dataset_preprocessed.zip\" data_multisspeaker\n",
        "  elif model_type.value == \"Un solo hablante\" or model_type == \"Un solo hablante (versi√≥n 3.2)\":\n",
        "    !zip \"{save_dir.value}/dataset_preprocessed.zip\" data\n",
        "  else:\n",
        "    raise Exception(\"No se reconoce el tipo de modelo. Recuerda que solo puedes elegir entre un solo hablante o varios.\")\n",
        "print(\"¬°Listo!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CoKJIkYvy_4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üöÄEntrenamiento 2: ForwardTacotron.\n",
        "#@markdown ---\n",
        "#@markdown Esto entrenar√° el modelo final para Forward Tacotron, tomando en cuenta el trabajo realizado anteriormente.\n",
        "#@markdown * Asimismo, cumplir√° un cronograma. Por defecto, se entrena hasta 300k pasos, pero puede funcionar con menos.\n",
        "#@markdown * Recuerda que se tomar√° en cuenta la atenci√≥n bas√°ndose en el modelo Tacotron. Si se est√° entrenando con pocos archivos debido a la mala atenci√≥n (Podemos darnos cuenta de esto durante el entrenamiento), hay un problema en el conjunto de datos. As√≠ que por favor, procura revisarlo, arreglar lo que sea necesario o aumentar m√°s datos.\n",
        "#@markdown * Puedes ajustar el tama√±o del lote (Batch) si no tienes memoria durante la sesi√≥n aqu√≠.\n",
        "batch_size = 24 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "# check TTS_model:\n",
        "config_path = check_config(model_type.value)\n",
        "config = read_config(config_path)\n",
        "if tts_model.value == \"forward_tacotron\":\n",
        "    config['forward_tacotron']['training']['schedule'] = ['5e-5,  150_000,  '+str(batch_size), '1e-5,  300_000,  '+str(batch_size)]\n",
        "elif tts_model.value == \"multi_forward_tacotron\":\n",
        "    config['multi_forward_tacotron']['training']['schedule'] = ['5e-5,  500_000,  '+str(batch_size), '1e-5,  600_000,  '+str(batch_size)]\n",
        "elif tts_model.value == \"fast_pitch\":\n",
        "    config['fast_pitch']['training']['schedule'] = ['1e-5,  5_000,  '+str(batch_size), '5e-5,  100_000,  '+str(batch_size), '2e-5,  300_000,  '+str(batch_size)]\n",
        "elif tts_model.value == \"multi_fast_pitch\":\n",
        "    config['multi_fast_pitch']['training']['schedule'] = ['1e-5,  5_000,  '+str(batch_size), '5e-5,  300_000,  '+str(batch_size), '2e-5,  600_000,  '+str(batch_size)]\n",
        "else:\n",
        "    raise Exception(f\"Este modelo TTS no est√° soportado: {tts_model.value}.\")\n",
        "save_config(config, config_path)\n",
        "#@markdown ---\n",
        "if only_singlespeaker_version:\n",
        "  !python train_forward.py\n",
        "else:\n",
        "  !python train_forward.py --config \"{config_path}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ox7B0EUizBgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßç¬øHas terminado de entrenar por hoy?üè†üö∂\n",
        "üîäPrueba el modelo en el cuaderno de s√≠ntesis pulsando [aqu√≠.](https://colab.research.google.com/drive/1yHdMGB5H6JG44TAN5BNcv7f95beN3qYZ)"
      ],
      "metadata": {
        "id": "of-AwqqvpR7K"
      }
    }
  ]
}
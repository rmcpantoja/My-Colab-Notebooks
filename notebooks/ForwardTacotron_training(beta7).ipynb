{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-ognVXccZjDg",
        "_TKXe-ttOtJh"
      ],
      "authorship_tag": "ABX9TyPVhZQxvtB5daCDyxwvutkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/ForwardTacotron_training(beta7).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Forward Tacotron` training notebook\n",
        "This notebook has been developed by [rmcpantoja](https://github.com/rmcpantoja)\n",
        "\n",
        "collaborator: [Xx_Nessu_XX](https://fakeyou.com/profile/Xx_Nessu_xX)\n",
        "\n",
        "## credits:\n",
        "\n",
        "* [as-ideas/ForwardTacotron repository](https://github.com/as-ideas/ForwardTacotron).\n",
        "\n",
        "\n",
        "### <ins>Important!</ins>:\n",
        "\n",
        "* For now, this notebook is not optimal for training with small datasets. I'm planning to retrain ljspeech dataset for tacotron. After that, small datasets can be trained.\n",
        "\n",
        "\n",
        "*last update: 2023/02/25*"
      ],
      "metadata": {
        "id": "uoBeS27om4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### check allocated GPU.\n",
        "#@markdown ---\n",
        "#@markdown You need at least one tesla t4, since the training process will take longer. If you have a GPU like k80, go to the menu bar and select runtime-disconnect and remove runtime.\n",
        "#@markdown * You can also run this notebook without a GPU (not recommended) by disabling hardware acceleration in the notebook settings.\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8XpLMaC8om1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### mount google drive.\n",
        "#@markdown ---\n",
        "#@markdown This is very important to store the checkpoints and preprocessed datasets that Forward Tacotron will be able to work with. However, some important notes:\n",
        "#@markdown * It's important that you verify your storage space in [Drive](http://drive.google.com/). Depending on the size of the dataset, you need to calculate a larger amount of available space.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GoIuX2WsqEHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## install process.\n",
        "#@markdown ---\n",
        "#@markdown This will install the synthesizer and other important dependencies.\n",
        "%cd /content\n",
        "import os\n",
        "from os.path import exists\n",
        "if (not os.path.exists(\"/content/ForwardTacotron\")):\n",
        "  print(\"Cloning repository...\")\n",
        "  !git clone https://github.com/as-ideas/ForwardTacotron\n",
        "else:\n",
        "  print(\"The working repository already exists. Skipping...\")\n",
        "# pip:\n",
        "!pip install numba librosa pyworld phonemizer webrtcvad PyYAML dataclasses soundfile scipy tensorboard matplotlib unidecode inflect resemblyzer==0.1.1-dev pandas\n",
        "#!pip install git+https://github.com/wkentaro/gdown.git\n",
        "%cd /content/ForwardTacotron\n",
        "!rm -r .git/\n",
        "#apt:\n",
        "!apt install espeak-ng\n",
        "!wget https://github.com/mikefarah/yq/releases/download/v4.29.2/yq_linux_amd64.tar.gz\n",
        "!tar -xvf yq_linux_amd64.tar.gz\n",
        "!mv /content/ForwardTacotron/yq_linux_amd64 /content/ForwardTacotron/yq\n",
        "#!bash install-man-page.sh\n",
        "print(\"ready\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kNbm8T4apkae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply patches.\n",
        "\n",
        "## **Please run after settings cell.**"
      ],
      "metadata": {
        "id": "pJR6gfEgBkwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"test\"\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n"
      ],
      "metadata": {
        "id": "wkjLCb05B7th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate /content/ForwardTacotron/utils/paths.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class Paths:\n",
        "    \"\"\"Manages and configures the paths used by WaveRNN, Tacotron, and the data.\"\"\"\n",
        "    def __init__(self, data_path, tts_id):\n",
        "\n",
        "        # directories\n",
        "        self.base = Path(__file__).parent.parent.expanduser().resolve()\n",
        "\n",
        "        # Data Paths\n",
        "        self.data = Path(data_path).expanduser().resolve()\n",
        "        self.quant = self.data/'quant'\n",
        "        self.mel = self.data/'mel'\n",
        "        self.gta = self.data/'gta'\n",
        "        self.att_pred = self.data/'att_pred'\n",
        "        self.alg = self.data/'alg'\n",
        "        self.speaker_emb = self.data/'speaker_emb'\n",
        "        self.mean_speaker_emb = self.data/'mean_speaker_emb'\n",
        "        self.raw_pitch = self.data/'raw_pitch'\n",
        "        self.phon_pitch = self.data/'phon_pitch'\n",
        "        self.phon_energy = self.data/'phon_energy'\n",
        "        self.model_output = self.base / 'model_output'\n",
        "        self.save_dir = Path(\"{save_dir}\").expanduser().resolve()\n",
        "        self.taco_checkpoints = self.save_dir/'checkpoints/{tts_id}.tacotron'\n",
        "        self.taco_log = self.taco_checkpoints / 'logs'\n",
        "        self.forward_checkpoints = self.save_dir/'checkpoints/{tts_id}.forward'\n",
        "        self.forward_log = self.forward_checkpoints/'logs'\n",
        "\n",
        "        # pickle objects\n",
        "        self.train_dataset = self.data / 'train_dataset.pkl'\n",
        "        self.val_dataset = self.data / 'val_dataset.pkl'\n",
        "        self.text_dict = self.data / 'text_dict.pkl'\n",
        "        self.speaker_dict = self.data / 'speaker_dict.pkl'\n",
        "        self.att_score_dict = self.data / 'att_score_dict.pkl'\n",
        "\n",
        "        self.create_paths()\n",
        "\n",
        "    def create_paths(self):\n",
        "        os.makedirs(self.data, exist_ok=True)\n",
        "        os.makedirs(self.quant, exist_ok=True)\n",
        "        os.makedirs(self.mel, exist_ok=True)\n",
        "        os.makedirs(self.gta, exist_ok=True)\n",
        "        os.makedirs(self.alg, exist_ok=True)\n",
        "        os.makedirs(self.speaker_emb, exist_ok=True)\n",
        "        os.makedirs(self.mean_speaker_emb, exist_ok=True)\n",
        "        os.makedirs(self.att_pred, exist_ok=True)\n",
        "        os.makedirs(self.raw_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_pitch, exist_ok=True)\n",
        "        os.makedirs(self.phon_energy, exist_ok=True)\n",
        "        os.makedirs(self.taco_checkpoints, exist_ok=True)\n",
        "        os.makedirs(self.forward_checkpoints, exist_ok=True)\n",
        "\n",
        "    def get_tts_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_weights.pyt'\n",
        "\n",
        "    def get_tts_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named tts checkpoint.\"\"\"\n",
        "        return self.taco_checkpoints / f'{name}_optim.pyt'\n",
        "\n",
        "    def get_voc_named_weights(self, name):\n",
        "        \"\"\"Gets the path for the weights in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_weights.pyt'\n",
        "\n",
        "    def get_voc_named_optim(self, name):\n",
        "        \"\"\"Gets the path for the optimizer state in a named voc checkpoint.\"\"\"\n",
        "        return self.voc_checkpoints/f'{name}_optim.pyt'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Eh2KwUoVB__x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# project preparation."
      ],
      "metadata": {
        "id": "Nsz7MI6nCJHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ForwardTacotron\n",
        "#@markdown ### settings.\n",
        "\n",
        "#@markdown These are some options with which we can modify settings related to data and training.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Choose the model variant to use:\n",
        "import os\n",
        "model_type = \"Single speaker\" #@param [\"Single speaker\", \"Multiple speakers\"]\n",
        "if model_type == \"Single speaker\":\n",
        "  config_path = \"configs/singlespeaker.yaml\"\n",
        "elif model_type == \"Multiple speakers\":\n",
        "  config_path = \"configs/multispeaker.yaml\"\n",
        "else:\n",
        "  raise Exception(\"Model type not supported. Currently, you can choose between a single speaker or multiple speakers.\")\n",
        "#@markdown ---\n",
        "#@markdown #### desired name for the TTS model\n",
        "tts_model_id = \"ExampleTTS\" #@param {type:\"string\"}\n",
        "tts_id = tts_model_id\n",
        "!./yq -i '.tts_model_id = \"{tts_model_id}\"' \"{config_path}\"\n",
        "#@markdown ---\n",
        "# waveRNN vocoder removed from last version\n",
        "#@markdown #### Choose the model type to be trained on this dataset:\n",
        "\n",
        "#@markdown The `multi_forward_tacotron` option is supported for multi-speaker models only.\n",
        "tts_model = \"forward_tacotron\" #@param [\"forward_tacotron\", \"multi_forward_tacotron\", \"fast_pitch\"]\n",
        "if tts_model == \"multi_forward_tacotron\" and model_type == \"Single speaker\":\n",
        "  raise Exception(\"The multi_forward_tacotron model is only supported on multi-speaker models.\")\n",
        "!./yq -i '.tts_model = \"{tts_model}\"' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### Continue training?\n",
        "continue_training = False #@param {type:\"boolean\"}\n",
        "#@markdown You can set the location of the preprocessed dataset that was saved to your Drive\n",
        "preprocess_path = \"/content/drive/MyDrive/ForwardTacotron/ExampleTTS/dataset_preprocessed.zip\" #@param {type:\"string\"}\n",
        "if continue_training:\n",
        "  !unzip $preprocess_path -d /content/FforwardTacotron\n",
        "#@markdown ---\n",
        "#@markdown #### Save checkpoints and preprocessing to a custom path?\n",
        "custom_save_dir = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown If it's this checkbox on, where do you want to save it?\n",
        "save_dir = \"/content/drive/MyDrive/ForwardTacotron/ExampleTTS\" #@param {type:\"string\"}\n",
        "if custom_save_dir:\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "else:\n",
        "  print(\"Warning! The changes will not be saved, only in the local folder of the project.\")\n",
        "  save_dir = \"/content/ForwardTacotron\"\n",
        "#@markdown ---\n",
        "#@markdown #### Choose the sample rate: (Optional)\n",
        "sample_rate = \"22050\" #@param [\"16000\", \"22050\", \"24000\", \"32000\", \"44100\", \"48000\"] {allow-input: true}\n",
        "!./yq -i '.dsp.sample_rate = {sample_rate}' \"{config_path}\"\n",
        "if sample_rate == \"16000\":\n",
        "  !./yq -i '.dsp.vad_sample_rate = 11025' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### Choose the transcript metafile format:\n",
        "\n",
        "#@markdown The `ljspeech` format is the only one used for single-speaker models.\n",
        "\n",
        "metafile_format = \"ljspeech\" #@param [\"ljspeech\", \"ljspeech_multi\", \"pandas\", \"vctk\"]\n",
        "if metafile_format == \"ljspeech\" and model_type == \"Varios hablantes\":\n",
        "  raise Exception(\"The ljspeech format is only compatible with single-speaker models.\")\n",
        "else:\n",
        "  !./yq -i '.preprocessing.metafile_format = \"{metafile_format}\"' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### Number of validation (You can adjust it according to the size of the dataset).\n",
        "n_val = 100 #@param {type:\"integer\"}\n",
        "!./yq -i '.preprocessing.n_val = {n_val}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "#@markdown #### Choose the language variation in which you have this dataset:\n",
        "#@markdown Here is a table to choose the desired language code:\n",
        "\n",
        "#@markdown Code|Language\n",
        "#@markdown en-029|English (Caribbean)\n",
        "#@markdown en-gb|English (Great Britain)\n",
        "#@markdown en-gb-scotland|English (Scotland)\n",
        "#@markdown en-gb-x-gbclan|English (Lancaster)\n",
        "#@markdown en-gb-x-gbcwmd|English (West Midlands)\n",
        "#@markdown en-gb-x-rp|English (Received Pronunciation)\n",
        "#@markdown en-us|English (America)\n",
        "\n",
        "language = 'en-us' #@param [\"en-029\", \"en-gb\", \"en-gb-scotland\", \"en-gb-x-gbclan\", \"en-gb-x-gbcwmd\", \"en-gb-x-rp\", \"en-us\"]\n",
        "!./yq -i '.preprocessing.language = \"{language}\"' \"{config_path}\"\n",
        "#@markdown ---\n",
        "# reduce workers in dur extraction:\n",
        "!./yq -i '.duration_extraction.num_workers = \"2\"' \"{config_path}\"\n",
        "#@markdown #### Step interval to generate model training signals\n",
        "#@markdown Here we can configure how many steps figures, images, visuals and audio will be generated, that is, the progress of the training that can be seen in tensorboard (in the following cells).\n",
        "#@markdown * Note: this setting will apply to all models: Tacotron, Forward_tacotron, multi_forward_tacotron (if training with multiple speakers), and FastPitch.\n",
        "plot_every = 5000 #@param {type:\"integer\"}\n",
        "!./yq -i '.tacotron.training.plot_every = {plot_every}' \"{config_path}\"\n",
        "if model_type == \"Multiple speakers\":\n",
        "  !./yq -i '.multi_forward_tacotron.training.plot_every = {plot_every}' \"{config_path}\"\n",
        "else:\n",
        "  !./yq -i '.forward_tacotron.training.plot_every = {plot_every}' \"{config_path}\"\n",
        "!./yq -i '.fast_pitch.training.plot_every = {plot_every}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "# phoneme singlespeaker:\n",
        "!./yq -i '.preprocessing.use_phonemes = \"True\"' \"{config_path}\"\n",
        "# attention:\n",
        "if model_type == \"Multiple speakers\":\n",
        "  !./yq -i '.multi_forward_tacotron.training.filter_attention = True' \"{config_path}\"\n",
        "  !./yq -i '.multi_forward_tacotron.training.min_attention_sharpness = 0.25' \"{config_path}\"\n",
        "  !./yq -i '.multi_forward_tacotron.training.min_attention_alignment = 0.5' \"{config_path}\"\n",
        "else:\n",
        "  !./yq -i '.forward_tacotron.training.filter_attention = True' \"{config_path}\"\n",
        "  !./yq -i '.forward_tacotron.training.min_attention_sharpness = 0.25' \"{config_path}\"\n",
        "  !./yq -i '.forward_tacotron.training.min_attention_alignment = 0.5' \"{config_path}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "JDfQsoTXqHnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## working with the dataset.\n",
        "\n",
        "**You can skip these cells if you have already preprocessed a dataset for the first time and want to train it on the last saved checkpoint. Otherwise, expand this section and read the instructions for each cell.**"
      ],
      "metadata": {
        "id": "-ognVXccZjDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import os.path\n",
        "#@markdown ### dataset preprocessing.\n",
        "#@markdown ---\n",
        "#@markdown * Note: If you are going to preprocess larger datasets, it is recommended to have more space available on your drive.\n",
        "#@markdown ---\n",
        "#@markdown #### wavs path (zip file):\n",
        "wavs_path = \"/content/drive/MyDrive/Wavs_m.zip\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Transcription Path: (By default metadata.csv)\n",
        "list_path = \"/content/drive/MyDrive/list_m.txt\" #@param {type:\"string\"}\n",
        "list_filename = os.path.basename(list_path).split('/')[-1]\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "!mkdir dataset\n",
        "%cd dataset\n",
        "!mkdir wavs\n",
        "if zipfile.is_zipfile(wavs_path):\n",
        "  !unzip -j \"$wavs_path\" -d /content/ForwardTacotron/wavs\n",
        "else:\n",
        "  print(\"Warning: the wavs path is not a compressed file.\")\n",
        "if list_path.endswith('.txt'):\n",
        "  raise Exception(\"The transcript format should be in csv extension.\")\n",
        "if not os.path.exists(list_path):\n",
        "  raise Exception(\"Error: Transcript file does not exist, please try again.\")\n",
        "else:\n",
        "  !cp $list_path /content/ForwardTacotron\n",
        "%cd /content/ForwardTacotron\n",
        "print(\"Running preprocess...\")\n",
        "!python preprocess.py --path /content/dataset --config \"{config_path}\" --metafile \"{list_filename}\"\n",
        "if custom_save_dir:\n",
        "  print(\"Backing up preprocessed data...\")\n",
        "  !zip -r \"$save_dir/dataset_preprocessed.zip\" configs data"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DeVSn6JGtLwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='red'>Caution!</font> You should run this cell if you have a dataset in your forward tacotron and want to train another. The contents will be deleted."
      ],
      "metadata": {
        "id": "_TKXe-ttOtJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### remove the current dataset (if it exists):\n",
        "#@markdown ---\n",
        "#@markdown Since the datasets are in the working folder, you may need to train another dataset. If so, run this cell to do so.\n",
        "# dataset\n",
        "!rm -rf /content/ForwardTacotron/dataset\n",
        "# preprocessed:\n",
        "!rm -rf /content/ForwardTacotron/data/*"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iSGxbKxXLuGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train!\n",
        "These steps will require time to achieve a stable training and after hours, and sometimes a few days, to obtain the final results. Please, I suggest carefully reading the indications of each of the cells.\n",
        "\n",
        "***LJSpeech pretrained model soon!***"
      ],
      "metadata": {
        "id": "z18_1tmByBTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Run tensorboard extension.\n",
        "#@markdown --\n",
        "#@markdown The tensorboard is used to visualize the model training process. Note that if you want to visualize this, you can go to the **audio**, **image** or **scalars** tabs.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"{data_path}/checkpoints\"\n",
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "id": "SXYKGmDHus0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Train 1: Tacotron.\n",
        "#@markdown ---\n",
        "#@markdown A point to take into account between Tacotron and Forward Tacotron is the training division.\n",
        "#@markdown * The model will be trained between a total of 40k steps. By default, backups are saved every 10k steps, so we should be concerned about storage. ___(Instead, you can delete the old backups. Also, the one that really matters and is used is the latest_model.pt checkpoint that is saved most often.)___\n",
        "#@markdown * Likewise, this training complies with a schedule which will apply different parameters.\n",
        "#@markdown\n",
        "#@markdown Let's train!\n",
        "\n",
        "!python train_tacotron.py --config \"{config_path}\"\n",
        "# include att score, pitch, att, aligments and more:\n",
        "print(\"But first, backing up the work that's just been done...\")\n",
        "!zip –u \"$save_dir/dataset_preprocessed.zip\" configs data\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "CoKJIkYvy_4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Train 2: Forward Tacotron.\n",
        "#@markdown ---\n",
        "#@markdown This will train the final model for Forward Tacotron, taking into account the work done previously.\n",
        "#@markdown * It will also follow a schedule. By default, it trains up to 300k steps, but it can work with less.\n",
        "#@markdown * Please note that care will be taken into account based on the tacotron model. If you are training with few files due to bad attention (we can tell this when training starts) there is a problem in the dataset, so please try to review it, fix what is necessary, add more data or revise carefully the Tensorboard.\n",
        "#@markdown * You can adjust the batch size if you are out of memory during the session here.\n",
        "batch_size = 24 #@param {type:\"integer\"}\n",
        "!./yq -i '.forward_tacotron.training.schedule[0] = 5e-5,  150_000,  {batch_size}' \"{config_path}\"\n",
        "!./yq -i '.forward_tacotron.training.schedule[1] = 1e-5,  300_000,  {batch_size}' \"{config_path}\"\n",
        "#@markdown ---\n",
        "!python train_forward.py --config \"{config_path}\""
      ],
      "metadata": {
        "id": "Ox7B0EUizBgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Have you finished training for today?\n",
        "Test the model in the synthesis notebook by clicking [here.](https://colab.research.google.com/drive/1yHdMGB5H6JG44TAN5BNcv7f95beN3qYZ)"
      ],
      "metadata": {
        "id": "FasTazpjLTAz"
      }
    }
  ]
}
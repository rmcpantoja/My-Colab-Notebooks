{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hg2HXNH3S63I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670244565756,"user_tz":300,"elapsed":516,"user":{"displayName":"Mateo Cedillo","userId":"00980018008011973725"}},"outputId":"99851eed-5f48-4f2c-89f9-2f98266c35aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-aaeee1db-9652-6d1c-8dec-b64fe663c6d2)\n"]}],"source":["# check GPU\n","!nvidia-smi -L"]},{"cell_type":"code","source":["# mount gdrive/drive/google drive\n","from google.colab import drive\n","drive.mount('drive', force_remount=True)"],"metadata":{"id":"9BM3B0JgTL59","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670244592709,"user_tz":300,"elapsed":25015,"user":{"displayName":"Mateo Cedillo","userId":"00980018008011973725"}},"outputId":"953283b7-7676-4561-b630-a08c1fb776b5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}]},{"cell_type":"code","source":["# clone\n","%cd /content\n","!git clone https://github.com/as-ideas/DeepPitchExtractor\n","%cd DeepPitchExtractor\n","!pip install pyworld"],"metadata":{"id":"a0VqGaZMTQ_g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670244672237,"user_tz":300,"elapsed":29811,"user":{"displayName":"Mateo Cedillo","userId":"00980018008011973725"}},"outputId":"f4536fa6-6ebe-4dbf-8e54-5dbd926ba2b3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","fatal: destination path 'DeepPitchExtractor' already exists and is not an empty directory.\n","/content/DeepPitchExtractor\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyworld\n","  Downloading pyworld-0.3.2.tar.gz (214 kB)\n","\u001b[K     |████████████████████████████████| 214 kB 19.0 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from pyworld) (0.29.32)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyworld) (1.21.6)\n","Building wheels for collected packages: pyworld\n","  Building wheel for pyworld (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyworld: filename=pyworld-0.3.2-cp38-cp38-linux_x86_64.whl size=673637 sha256=60cea7f8b9f4b1a18b6329b9035e0b35bb2542dba1f8901039abef657dcdfa41\n","  Stored in directory: /root/.cache/pip/wheels/b7/b1/d2/8c78d691f7d5b0bb4ba9993926db209429c92686476837627f\n","Successfully built pyworld\n","Installing collected packages: pyworld\n","Successfully installed pyworld-0.3.2\n"]}]},{"cell_type":"code","source":["%%writefile /content/DeepPitchExtractor/preprocess.py\n","from random import Random\n","\n","import pyworld as pw\n","import torch\n","import librosa\n","import numpy as np\n","from typing import Dict, Any, Tuple, Union\n","\n","import tqdm\n","import argparse\n","from multiprocessing import Pool, cpu_count\n","from pathlib import Path\n","\n","from dpe.audio import AudioProcessor\n","from dpe.utils import read_config, pickle_binary\n","\n","\n","def valid_n_workers(num: int) -> int:\n","    n = int(num)\n","    if n < 1:\n","        raise argparse.ArgumentTypeError('%r must be an integer greater than 0' % num)\n","    return n\n","\n","\n","class Preprocessor:\n","\n","    def __init__(self,\n","                 data_dir: Path,\n","                 audio_processor: AudioProcessor) -> None:\n","        self._data_dir = data_dir\n","        self._spec_dir = self._data_dir / 'specs'\n","        self._pitch_dir = self._data_dir / 'pitches'\n","        self._spec_dir.mkdir(parents=True, exist_ok=True)\n","        self._pitch_dir.mkdir(parents=True, exist_ok=True)\n","        self._audio = audio_processor\n","        pass\n","\n","    def __call__(self, path: Path) -> Union[Tuple[str, int], None]:\n","        try:\n","            item_id = path.stem\n","            wav, _ = librosa.load(str(path))\n","            spec = librosa.stft(\n","                y=wav,\n","                n_fft=self._audio.n_fft,\n","                hop_length=self._audio.hop_length,\n","                win_length=self._audio.win_length)\n","            spec = np.abs(spec)\n","            spec = torch.tensor(spec).float()\n","            pitch, _ = pw.dio(wav.astype(np.float64), self._audio.sample_rate,\n","                              frame_period=self._audio.hop_length / self._audio.sample_rate * 1000)\n","            pitch = torch.tensor(pitch).float()\n","            torch.save(spec, self._spec_dir / f'{item_id}.pt')\n","            torch.save(pitch, self._pitch_dir / f'{item_id}.pt')\n","            spec_len = spec.shape[-1]\n","            return item_id, spec_len\n","        except BaseException as e:\n","            print(e)\n","            return None\n","\n","\n","parser = argparse.ArgumentParser(description='Preprocessing for WaveRNN and Tacotron')\n","parser.add_argument('--path', '-p', help='directly point to dataset path')\n","parser.add_argument('--num_workers', '-w', metavar='N', type=valid_n_workers, default=cpu_count()-1, help='The number of worker threads to use for preprocessing')\n","parser.add_argument('--config', metavar='FILE', default='config.yaml', help='The config containing all hyperparams.')\n","args = parser.parse_args()\n","\n","\n","if __name__ == '__main__':\n","    config = read_config(args.config)\n","    print(config)\n","#    print(Path(config['paths/log_dir']))\n","    data_dir = Path(config[['data_dir']])\n","    wav_files = list(Path(args.path).glob('**/*.wav'))\n","    n_workers = max(1, args.num_workers)\n","    pool = Pool(processes=n_workers)\n","    audio = AudioProcessor(**config['audio'])\n","    preprocessor = Preprocessor(data_dir=data_dir, audio_processor=audio)\n","    dataset = []\n","    for data_point in tqdm.tqdm(pool.imap_unordered(preprocessor, wav_files), total=len(wav_files)):\n","        if data_point is not None:\n","            dataset.append(data_point)\n","    Random(42).shuffle(dataset)\n","    num_val = config['training']['n_val']\n","    val_dataset = dataset[:num_val]\n","    train_dataset = dataset[num_val:]\n","    pickle_binary(train_dataset, data_dir / 'train_dataset.pkl')\n","    pickle_binary(val_dataset, data_dir / 'val_dataset.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GlRhqnpRaXBV","executionInfo":{"status":"ok","timestamp":1670247110468,"user_tz":300,"elapsed":454,"user":{"displayName":"Mateo Cedillo","userId":"00980018008011973725"}},"outputId":"5c3f1916-2f4e-4645-8b56-85ad1a3e8272"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/DeepPitchExtractor/preprocess.py\n"]}]},{"cell_type":"code","source":["%%writefile /content/DeepPitchExtractor/config.yaml\n","paths:\n","  data_dir: 'data'\n","  checkpoint_dir: 'checkpoints'\n","  log_dir: 'pitch_log'\n","\n","audio:\n","  sample_rate: 22050\n","  n_fft: 1024\n","  hop_length: 256\n","  win_length: 1024\n","  pitch_min: 50\n","  pitch_max: 500\n","\n","training:\n","  n_val: 100\n","  batch_size: 32\n","  n_epochs: 1000\n","\n","model:\n","  conv_channels: 256\n","  out_channels: 512\n","  dropout: 0.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SO5FVrrNY7Ec","executionInfo":{"status":"ok","timestamp":1670246477884,"user_tz":300,"elapsed":380,"user":{"displayName":"Mateo Cedillo","userId":"00980018008011973725"}},"outputId":"d6b84b3d-2bb1-42ba-b0e4-cf7cf48b4ea3"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/DeepPitchExtractor/config.yaml\n"]}]},{"cell_type":"code","source":["# preprocessing:\n","%cd /content/DeepPitchExtractor\n","!mkdir audiodataset\n","wavs_path = \"/content/drive/MyDrive/Fakeyou/oriol/wavs2.zip\" #@param {type:\"string\"}\n","#!unzip -j \"$wavs_path\" -d /content/DeepPitchExtractor/audiodataset\n","!mv /content/DeepPitchExtractor/dpe/train.py /content/DeepPitchExtractor\n","!mv /content/DeepPitchExtractor/dpe/preprocess.py /content/DeepPitchExtractor\n","!mv /content/DeepPitchExtractor/dpe/predict.py /content/DeepPitchExtractor\n","!mv /content/DeepPitchExtractor/dpe/dataset.py /content/DeepPitchExtractor\n","!mv /content/DeepPitchExtractor/dpe/config.yaml /content/DeepPitchExtractor\n","#!mkdir data\n","!mkdir data/specs\n","!mkdir data/pitches\n","#!mkdir dpe/data\n","!python preprocess.py --path /content/DeepPitchExtractor/audiodataset\n","print(\"Listo.\")"],"metadata":{"id":"mO51kmFBTev5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670247115002,"user_tz":300,"elapsed":2221,"user":{"displayName":"Mateo Cedillo","userId":"00980018008011973725"}},"outputId":"e38b08fb-b321-4d2f-bba9-e4b5dcb1027c"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DeepPitchExtractor\n","mkdir: cannot create directory ‘audiodataset’: File exists\n","mv: cannot stat '/content/DeepPitchExtractor/dpe/train.py': No such file or directory\n","mv: cannot stat '/content/DeepPitchExtractor/dpe/preprocess.py': No such file or directory\n","mv: cannot stat '/content/DeepPitchExtractor/dpe/predict.py': No such file or directory\n","mv: cannot stat '/content/DeepPitchExtractor/dpe/dataset.py': No such file or directory\n","mv: cannot stat '/content/DeepPitchExtractor/dpe/config.yaml': No such file or directory\n","mkdir: cannot create directory ‘data/specs’: File exists\n","mkdir: cannot create directory ‘data/pitches’: File exists\n","{'paths': {'data_dir': 'data', 'checkpoint_dir': 'checkpoints', 'log_dir': 'pitch_log'}, 'audio': {'sample_rate': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': 1024, 'pitch_min': 50, 'pitch_max': 500}, 'training': {'n_val': 100, 'batch_size': 32, 'n_epochs': 1000}, 'model': {'conv_channels': 256, 'out_channels': 512, 'dropout': 0.5}}\n","Traceback (most recent call last):\n","  File \"preprocess.py\", line 72, in <module>\n","    data_dir = Path(config[['data_dir']])\n","TypeError: unhashable type: 'list'\n","Listo.\n"]}]}]}